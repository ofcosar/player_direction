{"cells":[{"cell_type":"markdown","metadata":{"id":"uL9gmGg_7O6V"},"source":["# üéØ Hyperparameter Tuning Round 4 - Dropout Fine-Tuning\n","### Player Direction Prediction - Precision Dropout Optimization\n","\n","**Round 3 Best:** MAE=55.34¬∞ (LR=2.07e-04, WD=1e-04, DR=0.45)\n","\n","**Round 4 Strategy:**\n","- ‚úÖ Fixed BS=32\n","- ‚úÖ Fixed WD=1e-04  \n","- ‚úÖ Fixed LR=2.07e-04 (best score: mean+std=65.87, achieved best MAE)\n","- üîç Explore DR with FINE granularity: 0.025 steps around 0.45-0.60\n","- **Total: 9 experiments (~1 hour on A100)**"]},{"cell_type":"markdown","metadata":{"id":"YAJtu9KL7O6Y"},"source":["## 1. Setup & Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfWDOLrk7O6Y","outputId":"4cdc8ea0-9b3b-4132-bfad-fee3c05c7526","executionInfo":{"status":"ok","timestamp":1766567133051,"user_tz":-180,"elapsed":15,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Round 4: Dropout Fine-Tuning\n","   Total: 9 experiments\n","   LR (FIXED): 0.00021 ‚≠ê\n","   WD (FIXED): 0.00010\n","   BS (FIXED): 32\n","   DR values: [0.4, 0.425, 0.45, 0.475, 0.5, 0.525, 0.55, 0.575, 0.6]\n","   Time: ~1 hour on A100\n"]}],"source":["# Base configuration\n","BASE_CONFIG = {\n","    'data_root': '/content/drive/MyDrive/player_direction_dataset',\n","    'results_dir': '/content/drive/MyDrive/hyperparameter_tuning_results_round4',\n","    'num_workers': 2,\n","    'pin_memory': True,\n","}\n","\n","# ROUND 4: DROPOUT FINE-TUNING (9 experiments)\n","# LR=2.07e-04: Best score (mean+std=65.87) AND achieved best absolute MAE (55.34¬∞)\n","# DR: Fine granularity around optimal region (0.45-0.60)\n","HYPERPARAMETER_GRID = {\n","    'learning_rate': [2.07e-04],  # FIXED (best from Round 3)\n","    'batch_size': [32],           # FIXED\n","    'weight_decay': [1e-04],      # FIXED\n","\n","    # Fine-grained dropout exploration\n","    'dropout': [\n","        0.400,  # -0.05 from best\n","        0.425,\n","        0.450,  # Best minimum from Round 3\n","        0.475,\n","        0.500,  # Best mean from Round 3\n","        0.525,\n","        0.550,\n","        0.575,\n","        0.600\n","    ],  # 9 values with 0.025 step\n","}\n","\n","FIXED_PARAMS = {\n","    'backbone': 'resnet34',\n","    'num_epochs': 100,\n","    'early_stopping_patience': 20,\n","    'early_stopping_min_delta': 0.5,\n","    'gradient_accumulation_steps': 2,\n","    'use_amp': True,\n","}\n","\n","total_combinations = (len(HYPERPARAMETER_GRID['learning_rate']) *\n","                     len(HYPERPARAMETER_GRID['batch_size']) *\n","                     len(HYPERPARAMETER_GRID['weight_decay']) *\n","                     len(HYPERPARAMETER_GRID['dropout']))\n","\n","assert total_combinations == 9\n","assert len(HYPERPARAMETER_GRID['dropout']) == 9\n","\n","print(f\"‚úÖ Round 4: Dropout Fine-Tuning\")\n","print(f\"   Total: {total_combinations} experiments\")\n","print(f\"   LR (FIXED): {HYPERPARAMETER_GRID['learning_rate'][0]:.5f} ‚≠ê\")\n","print(f\"   WD (FIXED): {HYPERPARAMETER_GRID['weight_decay'][0]:.5f}\")\n","print(f\"   BS (FIXED): {HYPERPARAMETER_GRID['batch_size'][0]}\")\n","print(f\"   DR values: {HYPERPARAMETER_GRID['dropout']}\")\n","print(f\"   Time: ~1 hour on A100\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDYcKd8l7O6a","outputId":"55a895ac-c564-49b5-a4db-bbe97ee7fb28","executionInfo":{"status":"ok","timestamp":1766567149439,"user_tz":-180,"elapsed":16387,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Using device: cuda\n","   GPU: Tesla T4\n","   Memory: 15.8 GB\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","from torchvision import transforms, models\n","from pathlib import Path\n","import json\n","import math\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","import time\n","import pandas as pd\n","from datetime import datetime\n","import itertools\n","import os\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"‚úÖ Using device: {device}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"]},{"cell_type":"markdown","metadata":{"id":"XQ36eTFO7O6a"},"source":["## 2. Configuration"]},{"cell_type":"markdown","metadata":{"id":"IT3D0jLq7O6b"},"source":["## 3. Dataset Class"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhqaeQ25m1Oy","executionInfo":{"status":"ok","timestamp":1766567200566,"user_tz":-180,"elapsed":18315,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"95e37423-7e53-4766-afce-138624b64a9a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWYFs6b-7O6b","outputId":"93135fdc-ab0d-46b0-cbe6-d80eb646758d","executionInfo":{"status":"ok","timestamp":1766567149439,"user_tz":-180,"elapsed":17,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Dataset class defined\n"]}],"source":["class PlayerDirectionDataset(Dataset):\n","    def __init__(self, root_dir, split='train', transform=None):\n","        if split == 'val':\n","            split = 'valid'\n","\n","        self.root_dir = Path(root_dir) / split\n","        self.transform = transform\n","\n","        labels_file = self.root_dir / 'labels.json'\n","        with open(labels_file, 'r') as f:\n","            labels_list = json.load(f)\n","\n","        self.labels = {item['filename']: item['direction_degree'] for item in labels_list}\n","        self.image_files = list(self.labels.keys())\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.image_files[idx]\n","        img_path = self.root_dir / 'images' / img_name\n","\n","        image = Image.open(img_path).convert('RGB')\n","        angle_deg = self.labels[img_name]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        angle_rad = math.radians(angle_deg)\n","\n","        return {\n","            'image': image,\n","            'sin': torch.tensor(math.sin(angle_rad), dtype=torch.float32),\n","            'cos': torch.tensor(math.cos(angle_rad), dtype=torch.float32),\n","            'angle_deg': torch.tensor(angle_deg, dtype=torch.float32)\n","        }\n","\n","print(\"‚úÖ Dataset class defined\")"]},{"cell_type":"markdown","metadata":{"id":"LTJc-xhP7O6c"},"source":["## 4. Model Architecture"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPd2yf4d7O6c","outputId":"e54e9805-9719-4ee8-ea19-0d20a80d75ba","executionInfo":{"status":"ok","timestamp":1766567149492,"user_tz":-180,"elapsed":58,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Model architecture defined\n"]}],"source":["class PlayerDirectionPredictor(nn.Module):\n","    def __init__(self, dropout=0.5):\n","        super().__init__()\n","\n","        resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n","        self.features = nn.Sequential(*list(resnet.children())[:-1])\n","\n","        self.head = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(128, 2)\n","        )\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        sin_cos = self.head(features)\n","        sin_cos = nn.functional.normalize(sin_cos, p=2, dim=1)\n","        return sin_cos\n","\n","    def predict_angle(self, x):\n","        sin_cos = self.forward(x)\n","        angle_rad = torch.atan2(sin_cos[:, 0], sin_cos[:, 1])\n","        angle_deg = torch.rad2deg(angle_rad) % 360\n","        return angle_deg\n","\n","class CircularLoss(nn.Module):\n","    def forward(self, pred, target_sin, target_cos):\n","        pred_sin, pred_cos = pred[:, 0], pred[:, 1]\n","        loss = 1 - (pred_sin * target_sin + pred_cos * target_cos)\n","        return loss.mean()\n","\n","print(\"‚úÖ Model architecture defined\")"]},{"cell_type":"markdown","metadata":{"id":"vZG7enQi7O6c"},"source":["## 5. Training Functions with Mixed Precision"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4z6nMNmL7O6c","outputId":"0f1f2b1f-8aaf-4663-9a76-835949b5ff1e","executionInfo":{"status":"ok","timestamp":1766567149549,"user_tz":-180,"elapsed":51,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Training functions defined with mixed precision\n"]}],"source":["def calculate_accuracy_metrics(pred_angles, target_angles, thresholds=[15, 30, 45]):\n","    \"\"\"Calculate accuracy at different angle thresholds\"\"\"\n","    errors = torch.abs(pred_angles - target_angles)\n","    # Handle circular nature (e.g., 359¬∞ and 1¬∞ are close)\n","    errors = torch.min(errors, 360 - errors)\n","\n","    metrics = {}\n","    for threshold in thresholds:\n","        acc = (errors <= threshold).float().mean().item() * 100\n","        metrics[f'acc{threshold}'] = acc\n","\n","    return metrics\n","\n","def train_epoch(model, loader, criterion, optimizer, device, use_amp=True, accumulation_steps=1):\n","    \"\"\"Train one epoch with mixed precision and gradient accumulation\"\"\"\n","    model.train()\n","    total_loss = 0\n","    all_pred_angles = []\n","    all_target_angles = []\n","\n","    scaler = GradScaler(enabled=use_amp)\n","    optimizer.zero_grad()\n","\n","    for batch_idx, batch in enumerate(loader):\n","        images = batch['image'].to(device)\n","        target_sin = batch['sin'].to(device)\n","        target_cos = batch['cos'].to(device)\n","        target_angles = batch['angle_deg'].to(device)\n","\n","        # Mixed precision forward pass\n","        with autocast(enabled=use_amp):\n","            pred = model(images)\n","            loss = criterion(pred, target_sin, target_cos)\n","            # Scale loss for gradient accumulation\n","            loss = loss / accumulation_steps\n","\n","        # Backward pass with gradient scaling\n","        scaler.scale(loss).backward()\n","\n","        # Update weights every accumulation_steps\n","        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(loader):\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        # Calculate metrics\n","        with torch.no_grad():\n","            pred_angles = model.predict_angle(images)\n","            all_pred_angles.append(pred_angles)\n","            all_target_angles.append(target_angles)\n","\n","        total_loss += loss.item() * accumulation_steps\n","\n","    all_pred_angles = torch.cat(all_pred_angles)\n","    all_target_angles = torch.cat(all_target_angles)\n","\n","    mae = torch.mean(torch.abs(all_pred_angles - all_target_angles)).item()\n","    metrics = calculate_accuracy_metrics(all_pred_angles, all_target_angles)\n","\n","    return total_loss / len(loader), mae, metrics\n","\n","def validate(model, loader, criterion, device, use_amp=True):\n","    \"\"\"Validate with mixed precision\"\"\"\n","    model.eval()\n","    total_loss = 0\n","    all_pred_angles = []\n","    all_target_angles = []\n","\n","    with torch.no_grad():\n","        for batch in loader:\n","            images = batch['image'].to(device)\n","            target_sin = batch['sin'].to(device)\n","            target_cos = batch['cos'].to(device)\n","            target_angles = batch['angle_deg'].to(device)\n","\n","            with autocast(enabled=use_amp):\n","                pred = model(images)\n","                loss = criterion(pred, target_sin, target_cos)\n","\n","            pred_angles = model.predict_angle(images)\n","            all_pred_angles.append(pred_angles)\n","            all_target_angles.append(target_angles)\n","\n","            total_loss += loss.item()\n","\n","    all_pred_angles = torch.cat(all_pred_angles)\n","    all_target_angles = torch.cat(all_target_angles)\n","\n","    mae = torch.mean(torch.abs(all_pred_angles - all_target_angles)).item()\n","    metrics = calculate_accuracy_metrics(all_pred_angles, all_target_angles)\n","\n","    return total_loss / len(loader), mae, metrics\n","\n","print(\"‚úÖ Training functions defined with mixed precision\")"]},{"cell_type":"markdown","metadata":{"id":"a4-PRNiQ7O6d"},"source":["## 6. Experiment Management"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Vnp2J67O6d","outputId":"fa794212-cbce-4d20-ec95-6fd20d6f2a46","executionInfo":{"status":"ok","timestamp":1766567149601,"user_tz":-180,"elapsed":51,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Experiment management functions defined\n","‚úÖ Test name: lr2e-04_bs32_wd1e-04_dr0.55\n","‚úÖ Naming function is CORRECT!\n"]}],"source":["def get_experiment_name(params):\n","    \"\"\"Generate unique experiment name from parameters\"\"\"\n","    # Use 2 decimals for dropout to avoid rounding (0.55 != 0.6)\n","    return f\"lr{params['learning_rate']:.0e}_bs{params['batch_size']}_wd{params['weight_decay']:.0e}_dr{params['dropout']:.2f}\"\n","\n","def check_if_completed(results_dir, exp_name):\n","    \"\"\"Check if experiment was already completed\"\"\"\n","    exp_dir = Path(results_dir) / exp_name\n","    if not exp_dir.exists():\n","        return False\n","\n","    result_file = exp_dir / 'result.json'\n","    if result_file.exists():\n","        with open(result_file, 'r') as f:\n","            result = json.load(f)\n","        return result.get('completed', False)\n","\n","    return False\n","\n","def save_results_to_excel(results_dir, all_results):\n","    \"\"\"Save all results to Excel file\"\"\"\n","    excel_file = Path(results_dir) / 'hyperparameter_tuning_results.xlsx'\n","\n","    # Flatten nested params dict for DataFrame\n","    flattened_results = []\n","    for result in all_results:\n","        flat_result = {\n","            'experiment_name': result['experiment_name'],\n","            'learning_rate': result['params']['learning_rate'],\n","            'batch_size': result['params']['batch_size'],\n","            'weight_decay': result['params']['weight_decay'],\n","            'dropout': result['params']['dropout'],\n","            'best_val_mae': result['best_val_mae'],\n","            'best_val_acc15': result['best_val_acc15'],\n","            'best_val_acc30': result['best_val_acc30'],\n","            'best_val_acc45': result['best_val_acc45'],\n","            'total_epochs': result['total_epochs'],\n","            'training_time_hours': result['training_time_hours'],\n","            'timestamp': result['timestamp']\n","        }\n","        flattened_results.append(flat_result)\n","\n","    df = pd.DataFrame(flattened_results)\n","    df = df.sort_values('best_val_mae')\n","\n","    df.to_excel(excel_file, index=False, engine='openpyxl')\n","    print(f\"\\nüìä Results saved to: {excel_file}\")\n","\n","    return excel_file\n","\n","print(\"‚úÖ Experiment management functions defined\")\n","\n","# TEST the function\n","test_params = {\n","    'learning_rate': 2.0e-04,\n","    'batch_size': 32,\n","    'weight_decay': 1e-04,\n","    'dropout': 0.55\n","}\n","test_name = get_experiment_name(test_params)\n","print(f\"‚úÖ Test name: {test_name}\")\n","assert test_name == \"lr2e-04_bs32_wd1e-04_dr0.55\", f\"ERROR: Name is wrong! Got {test_name}\"\n","print(f\"‚úÖ Naming function is CORRECT!\")"]},{"cell_type":"markdown","metadata":{"id":"validation_header"},"source":["## 6.5. üîç Validate Grid (Check for Duplicates)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"validation_code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766567149657,"user_tz":-180,"elapsed":55,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"11a9baa1-54c0-4e8c-cf84-5bfa977228c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Validating hyperparameter grid...\n","======================================================================\n","‚úÖ Total combinations: 9\n","‚úÖ LR values: [0.000207]\n","\n","‚úÖ SUCCESS: All 9 experiment names are UNIQUE!\n","\n","   Sample: lr2e-04_bs32_wd1e-04_dr0.40, lr2e-04_bs32_wd1e-04_dr0.42, ...\n","\n","======================================================================\n","‚úÖ Validation PASSED!\n","======================================================================\n"]}],"source":["# Validate hyperparameter grid\n","from collections import Counter\n","\n","print(\"üîç Validating hyperparameter grid...\")\n","print(\"=\" * 70)\n","\n","param_combinations_test = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","print(f\"‚úÖ Total combinations: {len(param_combinations_test)}\")\n","print(f\"‚úÖ LR values: {sorted(set([x[0] for x in param_combinations_test]))}\")\n","\n","exp_names = []\n","for lr, bs, wd, dropout in param_combinations_test:\n","    params = {'learning_rate': lr, 'batch_size': bs, 'weight_decay': wd, 'dropout': dropout}\n","    exp_name = get_experiment_name(params)\n","    exp_names.append(exp_name)\n","\n","name_counts = Counter(exp_names)\n","duplicates = {name: count for name, count in name_counts.items() if count > 1}\n","\n","if duplicates:\n","    print(f\"\\n‚ùå ERROR: Found {len(duplicates)} duplicate names!\")\n","    for i, (name, count) in enumerate(list(duplicates.items())[:10], 1):\n","        print(f\"   {i}. {name}: {count} times\")\n","    raise ValueError(f\"Fix HYPERPARAMETER_GRID in Cell 2!\")\n","else:\n","    print(f\"\\n‚úÖ SUCCESS: All {len(exp_names)} experiment names are UNIQUE!\")\n","    print(f\"\\n   Sample: {exp_names[0]}, {exp_names[1]}, ...\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"‚úÖ Validation PASSED!\")\n","print(\"=\" * 70)"]},{"cell_type":"markdown","metadata":{"id":"cleanup_header"},"source":["## 6.6. üßπ Cleanup Duplicates (Run Once Before Training)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"cleanup_code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766567149713,"user_tz":-180,"elapsed":55,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"46998967-b7ef-4a8e-e83b-06572963274a"},"outputs":[{"output_type":"stream","name":"stdout","text":["üßπ CLEANING UP DUPLICATES\n","======================================================================\n","\n","üìä Step 1: Cleaning Excel...\n","   ‚ö†Ô∏è  Excel not found\n","\n","üìÅ Step 2: Cleaning folders...\n","\n","======================================================================\n","‚úÖ CLEANUP COMPLETE!\n","======================================================================\n"]}],"source":["# Clean up duplicate experiments from folder and Excel\n","import shutil\n","from collections import defaultdict\n","\n","print(\"üßπ CLEANING UP DUPLICATES\")\n","print(\"=\" * 70)\n","\n","results_dir = Path(BASE_CONFIG['results_dir'])\n","excel_file = results_dir / 'hyperparameter_tuning_results.xlsx'\n","\n","# Step 1: Clean Excel\n","print(\"\\nüìä Step 1: Cleaning Excel...\")\n","if excel_file.exists():\n","    df = pd.read_excel(excel_file)\n","    print(f\"   Original: {len(df)} experiments\")\n","\n","    df['config'] = df.apply(\n","        lambda x: f\"{x['learning_rate']:.0e}_{x['batch_size']}_{x['weight_decay']:.0e}_{x['dropout']:.2f}\",\n","        axis=1\n","    )\n","\n","    duplicates = df[df.duplicated(subset='config', keep='first')]\n","\n","    if len(duplicates) > 0:\n","        print(f\"   Found {len(duplicates)} duplicates, removing...\")\n","        shutil.copy(excel_file, results_dir / 'results_BACKUP.xlsx')\n","        df_clean = df.drop_duplicates(subset='config', keep='first').drop(columns=['config'])\n","        df_clean.to_excel(excel_file, index=False, engine='openpyxl')\n","        print(f\"   ‚úÖ Cleaned: {len(df_clean)} unique experiments\")\n","    else:\n","        print(f\"   ‚úÖ No duplicates in Excel\")\n","else:\n","    print(f\"   ‚ö†Ô∏è  Excel not found\")\n","\n","# Step 2: Clean folders\n","print(\"\\nüìÅ Step 2: Cleaning folders...\")\n","if results_dir.exists():\n","    folders = [d for d in results_dir.iterdir() if d.is_dir()]\n","    print(f\"   Found {len(folders)} folders\")\n","\n","    experiments_by_config = defaultdict(list)\n","\n","    for folder in folders:\n","        result_file = folder / 'result.json'\n","        if result_file.exists():\n","            with open(result_file, 'r') as f:\n","                result = json.load(f)\n","                p = result['params']\n","                key = f\"{p['learning_rate']:.0e}_{p['batch_size']}_{p['weight_decay']:.0e}_{p['dropout']:.2f}\"\n","                experiments_by_config[key].append({\n","                    'folder': folder,\n","                    'mae': result['best_val_mae']\n","                })\n","\n","    to_remove = []\n","    for key, exps in experiments_by_config.items():\n","        if len(exps) > 1:\n","            print(f\"   Config {key}: {len(exps)} folders\")\n","            best = min(exps, key=lambda x: x['mae'])\n","            for exp in exps:\n","                if exp != best:\n","                    print(f\"      Remove: {exp['folder'].name} (MAE={exp['mae']:.2f}¬∞)\")\n","                    to_remove.append(exp['folder'])\n","                else:\n","                    print(f\"      Keep:   {exp['folder'].name} (MAE={exp['mae']:.2f}¬∞) ‚≠ê\")\n","\n","    if to_remove:\n","        print(f\"\\n   Removing {len(to_remove)} duplicate folders...\")\n","        for folder in to_remove:\n","            shutil.rmtree(folder)\n","        print(f\"   ‚úÖ Removed {len(to_remove)} folders\")\n","    else:\n","        print(f\"   ‚úÖ No duplicate folders\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"‚úÖ CLEANUP COMPLETE!\")\n","print(\"=\" * 70)"]},{"cell_type":"markdown","metadata":{"id":"uCv7IWsS7O6d"},"source":["## 7. Main Training Loop"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxP8YvTS7O6e","outputId":"31ed32e0-043d-4ffd-db30-a4d26ed281fe","executionInfo":{"status":"ok","timestamp":1766567149850,"user_tz":-180,"elapsed":136,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Main training loop defined\n"]}],"source":["def train_single_experiment(params, train_loader, val_loader, device, results_dir):\n","    \"\"\"Train a single hyperparameter configuration\"\"\"\n","\n","    exp_name = get_experiment_name(params)\n","    exp_dir = Path(results_dir) / exp_name\n","    exp_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # Initialize model\n","    model = PlayerDirectionPredictor(dropout=params['dropout']).to(device)\n","    criterion = CircularLoss()\n","    optimizer = optim.AdamW(\n","        model.parameters(),\n","        lr=params['learning_rate'],\n","        weight_decay=params['weight_decay']\n","    )\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7\n","    )\n","\n","    best_val_mae = float('inf')\n","    best_val_acc15 = 0\n","    best_val_acc30 = 0\n","    best_val_acc45 = 0\n","    patience_counter = 0\n","    history = []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(FIXED_PARAMS['num_epochs']):\n","        # Train\n","        train_loss, train_mae, train_metrics = train_epoch(\n","            model, train_loader, criterion, optimizer, device,\n","            use_amp=FIXED_PARAMS['use_amp'],\n","            accumulation_steps=FIXED_PARAMS['gradient_accumulation_steps']\n","        )\n","\n","        # Validate\n","        val_loss, val_mae, val_metrics = validate(\n","            model, val_loader, criterion, device,\n","            use_amp=FIXED_PARAMS['use_amp']\n","        )\n","\n","        # Update scheduler\n","        scheduler.step(val_mae)\n","\n","        # Save history\n","        epoch_data = {\n","            'epoch': epoch + 1,\n","            'train_loss': train_loss,\n","            'train_mae': train_mae,\n","            'train_acc15': train_metrics['acc15'],\n","            'train_acc30': train_metrics['acc30'],\n","            'train_acc45': train_metrics['acc45'],\n","            'val_loss': val_loss,\n","            'val_mae': val_mae,\n","            'val_acc15': val_metrics['acc15'],\n","            'val_acc30': val_metrics['acc30'],\n","            'val_acc45': val_metrics['acc45'],\n","            'lr': optimizer.param_groups[0]['lr']\n","        }\n","        history.append(epoch_data)\n","\n","        # Track best metrics\n","        if val_metrics['acc15'] > best_val_acc15:\n","            best_val_acc15 = val_metrics['acc15']\n","        if val_metrics['acc30'] > best_val_acc30:\n","            best_val_acc30 = val_metrics['acc30']\n","        if val_metrics['acc45'] > best_val_acc45:\n","            best_val_acc45 = val_metrics['acc45']\n","\n","        # Check for improvement\n","        if val_mae < best_val_mae - FIXED_PARAMS['early_stopping_min_delta']:\n","            best_val_mae = val_mae\n","            patience_counter = 0\n","\n","            # Save best model\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'val_mae': val_mae,\n","                'val_metrics': val_metrics,\n","                'params': params\n","            }, exp_dir / 'best_model.pth')\n","        else:\n","            patience_counter += 1\n","\n","        # Early stopping\n","        if patience_counter >= FIXED_PARAMS['early_stopping_patience']:\n","            break\n","\n","    training_time = (time.time() - start_time) / 3600\n","\n","    # Save history\n","    with open(exp_dir / 'history.json', 'w') as f:\n","        json.dump(history, f, indent=2)\n","\n","    # Save final result\n","    result = {\n","        'experiment_name': exp_name,\n","        'params': params,\n","        'best_val_mae': best_val_mae,\n","        'best_val_acc15': best_val_acc15,\n","        'best_val_acc30': best_val_acc30,\n","        'best_val_acc45': best_val_acc45,\n","        'total_epochs': len(history),\n","        'training_time_hours': training_time,\n","        'completed': True,\n","        'timestamp': datetime.now().isoformat()\n","    }\n","\n","    with open(exp_dir / 'result.json', 'w') as f:\n","        json.dump(result, f, indent=2)\n","\n","    return result\n","\n","print(\"‚úÖ Main training loop defined\")"]},{"cell_type":"markdown","metadata":{"id":"do1yQ4rx7O6e"},"source":["## 8. Test Maximum Batch Size (Optional)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y06DHSIZ7O6e","outputId":"aac0c22b-01e8-4637-dd85-389bba6bde25","executionInfo":{"status":"ok","timestamp":1766567161581,"user_tz":-180,"elapsed":11730,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Testing maximum batch size for your GPU...\n","\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 203MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Batch size  32: OK (GPU: 0.3 GB)\n","‚úÖ Batch size  64: OK (GPU: 0.6 GB)\n","‚úÖ Batch size  96: OK (GPU: 0.8 GB)\n","‚úÖ Batch size 128: OK (GPU: 1.0 GB)\n","‚úÖ Batch size 192: OK (GPU: 1.5 GB)\n","‚úÖ Batch size 256: OK (GPU: 2.0 GB)\n","‚úÖ Batch size 320: OK (GPU: 2.5 GB)\n","‚úÖ Batch size 384: OK (GPU: 2.9 GB)\n","‚úÖ Batch size 448: OK (GPU: 3.4 GB)\n","‚úÖ Batch size 512: OK (GPU: 3.9 GB)\n","\n","üéØ Maximum batch size: 512\n","üí° Your hyperparameter grid includes: [32]\n","   All batch sizes should work fine!\n"]}],"source":["print(\"üîç Testing maximum batch size for your GPU...\\n\")\n","\n","test_sizes = [32, 64, 96, 128, 192, 256, 320, 384, 448, 512]\n","max_batch_size = 32\n","\n","for bs in test_sizes:\n","    try:\n","        model = PlayerDirectionPredictor(dropout=0.5).to(device)\n","        test_batch = torch.randn(bs, 3, 224, 224).to(device)\n","\n","        with torch.no_grad():\n","            _ = model(test_batch)\n","\n","        max_batch_size = bs\n","        gpu_memory = torch.cuda.max_memory_allocated() / 1e9\n","        print(f\"‚úÖ Batch size {bs:3d}: OK (GPU: {gpu_memory:.1f} GB)\")\n","\n","        del model, test_batch\n","        torch.cuda.empty_cache()\n","\n","    except RuntimeError as e:\n","        if \"out of memory\" in str(e):\n","            print(f\"‚ùå Batch size {bs:3d}: Out of memory\")\n","            break\n","        raise e\n","\n","print(f\"\\nüéØ Maximum batch size: {max_batch_size}\")\n","print(f\"üí° Your hyperparameter grid includes: {HYPERPARAMETER_GRID['batch_size']}\")\n","print(f\"   All batch sizes should work fine!\")"]},{"cell_type":"markdown","metadata":{"id":"i6Qgi9hp7O6e"},"source":["## 9. Load Data (Once)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNjs5D_m7O6e","outputId":"65740711-c994-4e0a-8004-36e90d0d5763","executionInfo":{"status":"ok","timestamp":1766567210281,"user_tz":-180,"elapsed":2577,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üìÇ LOADING DATASETS\n","======================================================================\n","\n","‚úÖ Train: 1400 images\n","‚úÖ Val: 300 images\n","======================================================================\n"]}],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üìÇ LOADING DATASETS\")\n","print(\"=\"*70)\n","\n","# Data transforms\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load datasets\n","train_dataset = PlayerDirectionDataset(BASE_CONFIG['data_root'], 'train', train_transform)\n","val_dataset = PlayerDirectionDataset(BASE_CONFIG['data_root'], 'val', val_transform)\n","\n","print(f\"\\n‚úÖ Train: {len(train_dataset)} images\")\n","print(f\"‚úÖ Val: {len(val_dataset)} images\")\n","print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{"id":"vc3GlJ6X7O6e"},"source":["## 10. Run Hyperparameter Tuning"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz2nmIgW7O6f","outputId":"afb7e5e6-e67f-483f-e7d9-5cea75c71572","executionInfo":{"status":"ok","timestamp":1766572680945,"user_tz":-180,"elapsed":5469894,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Checking for duplicate experiment names...\n","‚úÖ All 9 experiment names are unique!\n","\n","üìä First 5 experiment names:\n","   1. lr2e-04_bs32_wd1e-04_dr0.40\n","   2. lr2e-04_bs32_wd1e-04_dr0.42\n","   3. lr2e-04_bs32_wd1e-04_dr0.45\n","   4. lr2e-04_bs32_wd1e-04_dr0.47\n","   5. lr2e-04_bs32_wd1e-04_dr0.50\n","\n","üìä Last 5 experiment names:\n","   5. lr2e-04_bs32_wd1e-04_dr0.50\n","   6. lr2e-04_bs32_wd1e-04_dr0.53\n","   7. lr2e-04_bs32_wd1e-04_dr0.55\n","   8. lr2e-04_bs32_wd1e-04_dr0.57\n","   9. lr2e-04_bs32_wd1e-04_dr0.60\n","\n","======================================================================\n","üöÄ STARTING HYPERPARAMETER TUNING\n","======================================================================\n","\n","üìä Total combinations to test: 9\n","‚öôÔ∏è  Mixed Precision: True\n","‚öôÔ∏è  Gradient Accumulation: 2x\n","\n","======================================================================\n","üîß Experiment 1/9: lr2e-04_bs32_wd1e-04_dr0.40\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.4\n","   Effective Batch: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4142847985.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler(enabled=use_amp)\n","/tmp/ipython-input-4142847985.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=use_amp):\n","/tmp/ipython-input-4142847985.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=use_amp):\n"]},{"output_type":"stream","name":"stdout","text":["\n","   ‚úÖ Best Val MAE: 60.41¬∞\n","   ‚úÖ Acc@15¬∞: 36.3%\n","   ‚úÖ Acc@30¬∞: 56.0%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.27 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 2/9: lr2e-04_bs32_wd1e-04_dr0.42\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.425\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.28¬∞\n","   ‚úÖ Acc@15¬∞: 33.3%\n","   ‚úÖ Acc@30¬∞: 57.0%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 3/9: lr2e-04_bs32_wd1e-04_dr0.45\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.45\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.95¬∞\n","   ‚úÖ Acc@15¬∞: 35.0%\n","   ‚úÖ Acc@30¬∞: 56.0%\n","   ‚úÖ Acc@45¬∞: 71.0%\n","   ‚è±Ô∏è  Time: 0.13 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 4/9: lr2e-04_bs32_wd1e-04_dr0.47\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.475\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 64.85¬∞\n","   ‚úÖ Acc@15¬∞: 31.3%\n","   ‚úÖ Acc@30¬∞: 53.0%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.23 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 5/9: lr2e-04_bs32_wd1e-04_dr0.50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 68.75¬∞\n","   ‚úÖ Acc@15¬∞: 31.7%\n","   ‚úÖ Acc@30¬∞: 52.0%\n","   ‚úÖ Acc@45¬∞: 68.7%\n","   ‚è±Ô∏è  Time: 0.12 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 6/9: lr2e-04_bs32_wd1e-04_dr0.53\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.525\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 65.95¬∞\n","   ‚úÖ Acc@15¬∞: 31.0%\n","   ‚úÖ Acc@30¬∞: 55.3%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.20 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 7/9: lr2e-04_bs32_wd1e-04_dr0.55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.35¬∞\n","   ‚úÖ Acc@15¬∞: 31.7%\n","   ‚úÖ Acc@30¬∞: 55.0%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 8/9: lr2e-04_bs32_wd1e-04_dr0.57\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.575\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.37¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 54.7%\n","   ‚úÖ Acc@45¬∞: 71.0%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 9/9: lr2e-04_bs32_wd1e-04_dr0.60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 68.93¬∞\n","   ‚úÖ Acc@15¬∞: 34.0%\n","   ‚úÖ Acc@30¬∞: 53.7%\n","   ‚úÖ Acc@45¬∞: 69.7%\n","   ‚è±Ô∏è  Time: 0.11 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üéâ HYPERPARAMETER TUNING COMPLETED!\n","======================================================================\n","‚úÖ Completed: 9\n","‚è≠Ô∏è  Skipped: 0\n","üìä Total results: 9\n","======================================================================\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round4/hyperparameter_tuning_results.xlsx\n","\n","üèÜ TOP 10 RESULTS:\n","======================================================================\n","1. lr2e-04_bs32_wd1e-04_dr0.42\n","   MAE: 59.28¬∞ | Acc@15¬∞: 33.3% | Acc@30¬∞: 57.0%\n","2. lr2e-04_bs32_wd1e-04_dr0.57\n","   MAE: 59.37¬∞ | Acc@15¬∞: 32.7% | Acc@30¬∞: 54.7%\n","3. lr2e-04_bs32_wd1e-04_dr0.40\n","   MAE: 60.41¬∞ | Acc@15¬∞: 36.3% | Acc@30¬∞: 56.0%\n","4. lr2e-04_bs32_wd1e-04_dr0.55\n","   MAE: 63.35¬∞ | Acc@15¬∞: 31.7% | Acc@30¬∞: 55.0%\n","5. lr2e-04_bs32_wd1e-04_dr0.45\n","   MAE: 63.95¬∞ | Acc@15¬∞: 35.0% | Acc@30¬∞: 56.0%\n","6. lr2e-04_bs32_wd1e-04_dr0.47\n","   MAE: 64.85¬∞ | Acc@15¬∞: 31.3% | Acc@30¬∞: 53.0%\n","7. lr2e-04_bs32_wd1e-04_dr0.53\n","   MAE: 65.95¬∞ | Acc@15¬∞: 31.0% | Acc@30¬∞: 55.3%\n","8. lr2e-04_bs32_wd1e-04_dr0.50\n","   MAE: 68.75¬∞ | Acc@15¬∞: 31.7% | Acc@30¬∞: 52.0%\n","9. lr2e-04_bs32_wd1e-04_dr0.60\n","   MAE: 68.93¬∞ | Acc@15¬∞: 34.0% | Acc@30¬∞: 53.7%\n","======================================================================\n"]}],"source":["# DEBUG: Check for duplicates\n","print(\"üîç Checking for duplicate experiment names...\")\n","from collections import Counter\n","\n","param_combinations_test = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","exp_names = []\n","for lr, bs, wd, dropout in param_combinations_test:\n","    params = {'learning_rate': lr, 'batch_size': bs, 'weight_decay': wd, 'dropout': dropout}\n","    exp_name = get_experiment_name(params)\n","    exp_names.append(exp_name)\n","\n","# Check for duplicates\n","name_counts = Counter(exp_names)\n","duplicates = {name: count for name, count in name_counts.items() if count > 1}\n","\n","if duplicates:\n","    print(f\"‚ùå Found {len(duplicates)} duplicate names:\")\n","    for name, count in list(duplicates.items())[:5]:\n","        print(f\"   {name}: appears {count} times\")\n","else:\n","    print(f\"‚úÖ All {len(exp_names)} experiment names are unique!\")\n","\n","print(f\"\\nüìä First 5 experiment names:\")\n","for i, name in enumerate(exp_names[:5]):\n","    print(f\"   {i+1}. {name}\")\n","\n","print(f\"\\nüìä Last 5 experiment names:\")\n","for i, name in enumerate(exp_names[-5:], len(exp_names)-4):\n","    print(f\"   {i}. {name}\")\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ STARTING HYPERPARAMETER TUNING\")\n","print(\"=\"*70)\n","\n","# Create results directory\n","results_dir = Path(BASE_CONFIG['results_dir'])\n","results_dir.mkdir(parents=True, exist_ok=True)\n","\n","# Generate all combinations\n","param_combinations = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","print(f\"\\nüìä Total combinations to test: {len(param_combinations)}\")\n","print(f\"‚öôÔ∏è  Mixed Precision: {FIXED_PARAMS['use_amp']}\")\n","print(f\"‚öôÔ∏è  Gradient Accumulation: {FIXED_PARAMS['gradient_accumulation_steps']}x\")\n","\n","# Track all results\n","all_results = []\n","completed_count = 0\n","skipped_count = 0\n","\n","for idx, (lr, bs, wd, dropout) in enumerate(param_combinations, 1):\n","    params = {\n","        'learning_rate': lr,\n","        'batch_size': bs,\n","        'weight_decay': wd,\n","        'dropout': dropout\n","    }\n","\n","    exp_name = get_experiment_name(params)\n","\n","    print(f\"\\n{'='*70}\")\n","    print(f\"üîß Experiment {idx}/{len(param_combinations)}: {exp_name}\")\n","    print(f\"{'='*70}\")\n","    print(f\"   LR: {lr:.0e}, Batch: {bs}, WD: {wd:.0e}, Dropout: {dropout}\")\n","    print(f\"   Effective Batch: {bs * FIXED_PARAMS['gradient_accumulation_steps']}\")\n","\n","    # Check if already completed\n","    if check_if_completed(results_dir, exp_name):\n","        print(f\"   ‚è≠Ô∏è  Already completed, skipping...\")\n","        skipped_count += 1\n","\n","        # Load existing result\n","        with open(results_dir / exp_name / 'result.json', 'r') as f:\n","            result = json.load(f)\n","        all_results.append(result)\n","        continue\n","\n","    try:\n","        # Create data loaders with current batch size\n","        train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=bs,\n","            shuffle=True,\n","            num_workers=BASE_CONFIG['num_workers'],\n","            pin_memory=BASE_CONFIG['pin_memory']\n","        )\n","\n","        val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=bs,\n","            shuffle=False,\n","            num_workers=BASE_CONFIG['num_workers'],\n","            pin_memory=BASE_CONFIG['pin_memory']\n","        )\n","\n","        # Train\n","        result = train_single_experiment(\n","            params, train_loader, val_loader, device, results_dir\n","        )\n","\n","        all_results.append(result)\n","        completed_count += 1\n","\n","        print(f\"\\n   ‚úÖ Best Val MAE: {result['best_val_mae']:.2f}¬∞\")\n","        print(f\"   ‚úÖ Acc@15¬∞: {result['best_val_acc15']:.1f}%\")\n","        print(f\"   ‚úÖ Acc@30¬∞: {result['best_val_acc30']:.1f}%\")\n","        print(f\"   ‚úÖ Acc@45¬∞: {result['best_val_acc45']:.1f}%\")\n","        print(f\"   ‚è±Ô∏è  Time: {result['training_time_hours']:.2f} hours\")\n","\n","        # Save results to Excel after each experiment\n","        save_results_to_excel(results_dir, all_results)\n","\n","        # Clear GPU cache\n","        torch.cuda.empty_cache()\n","\n","    except Exception as e:\n","        print(f\"\\n   ‚ùå Error in experiment {exp_name}: {str(e)}\")\n","        continue\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ HYPERPARAMETER TUNING COMPLETED!\")\n","print(\"=\"*70)\n","print(f\"‚úÖ Completed: {completed_count}\")\n","print(f\"‚è≠Ô∏è  Skipped: {skipped_count}\")\n","print(f\"üìä Total results: {len(all_results)}\")\n","print(\"=\"*70)\n","\n","# Final save\n","if all_results:\n","    excel_file = save_results_to_excel(results_dir, all_results)\n","\n","    # Show top 10 results\n","    sorted_results = sorted(all_results, key=lambda x: x['best_val_mae'])\n","    print(\"\\nüèÜ TOP 10 RESULTS:\")\n","    print(\"=\"*70)\n","    for i, res in enumerate(sorted_results[:10], 1):\n","        print(f\"{i}. {res['experiment_name']}\")\n","        print(f\"   MAE: {res['best_val_mae']:.2f}¬∞ | Acc@15¬∞: {res['best_val_acc15']:.1f}% | Acc@30¬∞: {res['best_val_acc30']:.1f}%\")\n","    print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{"id":"e0FplEL-7O6f"},"source":["## 11. Analyze Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDMD7OmV7O6f","executionInfo":{"status":"aborted","timestamp":1766567161621,"user_tz":-180,"elapsed":28828,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[],"source":["# Load results from Excel\n","excel_file = Path(BASE_CONFIG['results_dir']) / 'hyperparameter_tuning_results.xlsx'\n","\n","if excel_file.exists():\n","    df = pd.read_excel(excel_file)\n","\n","    print(\"\\nüìä HYPERPARAMETER ANALYSIS\")\n","    print(\"=\"*70)\n","\n","    # Best overall\n","    best = df.iloc[0]\n","    print(f\"\\nü•á BEST CONFIGURATION:\")\n","    print(f\"   Experiment: {best['experiment_name']}\")\n","    print(f\"   LR: {best['learning_rate']:.0e}, Batch: {best['batch_size']}, WD: {best['weight_decay']:.0e}, Dropout: {best['dropout']}\")\n","    print(f\"   Val MAE: {best['best_val_mae']:.2f}¬∞\")\n","    print(f\"   Acc@15¬∞: {best['best_val_acc15']:.1f}%\")\n","    print(f\"   Acc@30¬∞: {best['best_val_acc30']:.1f}%\")\n","    print(f\"   Acc@45¬∞: {best['best_val_acc45']:.1f}%\")\n","    print(f\"   Training time: {best['training_time_hours']:.2f} hours\")\n","\n","    # Statistics\n","    print(f\"\\nüìà OVERALL STATISTICS:\")\n","    print(f\"   Mean Val MAE: {df['best_val_mae'].mean():.2f}¬∞\")\n","    print(f\"   Std Val MAE: {df['best_val_mae'].std():.2f}¬∞\")\n","    print(f\"   Min Val MAE: {df['best_val_mae'].min():.2f}¬∞\")\n","    print(f\"   Max Val MAE: {df['best_val_mae'].max():.2f}¬∞\")\n","    print(f\"\\n   Mean Acc@30¬∞: {df['best_val_acc30'].mean():.1f}%\")\n","    print(f\"   Max Acc@30¬∞: {df['best_val_acc30'].max():.1f}%\")\n","\n","    # Best by learning rate\n","    print(f\"\\nüìä BEST BY LEARNING RATE:\")\n","    for lr in sorted(df['learning_rate'].unique()):\n","        lr_df = df[df['learning_rate'] == lr]\n","        best_lr = lr_df.iloc[0]\n","        print(f\"   LR {lr:.0e}: MAE {best_lr['best_val_mae']:.2f}¬∞ | Acc@30¬∞ {best_lr['best_val_acc30']:.1f}%\")\n","\n","    # Best by batch size\n","    print(f\"\\nüìä BEST BY BATCH SIZE:\")\n","    for bs in sorted(df['batch_size'].unique()):\n","        bs_df = df[df['batch_size'] == bs]\n","        best_bs = bs_df.iloc[0]\n","        print(f\"   Batch {bs:3d}: MAE {best_bs['best_val_mae']:.2f}¬∞ | Acc@30¬∞ {best_bs['best_val_acc30']:.1f}%\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(f\"üìÅ Full results saved to: {excel_file}\")\n","    print(\"=\"*70)\n","else:\n","    print(\"‚ö†Ô∏è No results file found. Run the tuning experiment first!\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}