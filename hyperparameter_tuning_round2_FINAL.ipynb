{"cells":[{"cell_type":"markdown","metadata":{"id":"uL9gmGg_7O6V"},"source":["# üéØ Hyperparameter Tuning - A100 Optimized\n","### Player Direction Prediction with Maximum GPU Utilization\n","\n","**Features:**\n","- A100-optimized batch sizes (32-256)\n","- Mixed precision training (FP16)\n","- Gradient accumulation\n","- Resume capability\n","- Excel tracking with Acc@15¬∞, Acc@30¬∞, Acc@45¬∞"]},{"cell_type":"markdown","metadata":{"id":"YAJtu9KL7O6Y"},"source":["## 1. Setup & Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfWDOLrk7O6Y","outputId":"994450aa-e5a3-4e90-b302-38c220609e91","executionInfo":{"status":"ok","timestamp":1766500875711,"user_tz":-180,"elapsed":66242,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Install required packages\n","!pip install -q openpyxl pandas"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDYcKd8l7O6a","outputId":"cff4be8c-3643-42b7-ff05-92adc667ee0f","executionInfo":{"status":"ok","timestamp":1766500889967,"user_tz":-180,"elapsed":14248,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Using device: cuda\n","   GPU: Tesla T4\n","   Memory: 15.8 GB\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","from torchvision import transforms, models\n","from pathlib import Path\n","import json\n","import math\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","import time\n","import pandas as pd\n","from datetime import datetime\n","import itertools\n","import os\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"‚úÖ Using device: {device}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"]},{"cell_type":"markdown","metadata":{"id":"XQ36eTFO7O6a"},"source":["## 2. Configuration"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ws26vRHi7O6a","outputId":"30f224ba-b97b-44cb-cc02-001852d5cb4c","executionInfo":{"status":"ok","timestamp":1766500890000,"user_tz":-180,"elapsed":19,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Round 2: Refined Hyperparameter Search (VALIDATED)\n","   Total combinations: 100\n","   LR values (5): [0.00015, 0.00018, 0.0002, 0.00022, 0.00025]\n","   WD values (5): [0, 5e-05, 0.0001, 0.0002, 0.0005]\n","   DR values (4): [0.5, 0.55, 0.6, 0.65]\n","   Mixed Precision: True\n","   Batch size (FIXED): 32\n"]}],"source":["# Base configuration\n","BASE_CONFIG = {\n","    'data_root': '/content/drive/MyDrive/player_direction_dataset',\n","    'results_dir': '/content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed',\n","    'num_workers': 2,\n","    'pin_memory': True,\n","}\n","\n","# ROUND 2: Refined parameters - CORRECTED (NO DUPLICATES!)\n","HYPERPARAMETER_GRID = {\n","    'learning_rate': [1.5e-04, 1.8e-04, 2.0e-04, 2.2e-04, 2.5e-04],  # Exactly 5 UNIQUE values\n","    'batch_size': [32],  # 1 value (FIXED)\n","    'weight_decay': [0, 5e-05, 1e-04, 2e-04, 5e-04],  # 5 values\n","    'dropout': [0.50, 0.55, 0.60, 0.65],  # 4 values\n","}\n","\n","# Fixed parameters\n","FIXED_PARAMS = {\n","    'backbone': 'resnet34',\n","    'num_epochs': 100,\n","    'early_stopping_patience': 20,\n","    'early_stopping_min_delta': 0.5,\n","    'gradient_accumulation_steps': 2,\n","    'use_amp': True,\n","}\n","\n","# Validate grid\n","total_combinations = (len(HYPERPARAMETER_GRID['learning_rate']) *\n","                     len(HYPERPARAMETER_GRID['batch_size']) *\n","                     len(HYPERPARAMETER_GRID['weight_decay']) *\n","                     len(HYPERPARAMETER_GRID['dropout']))\n","\n","# CRITICAL: Check for duplicates\n","assert total_combinations == 100, f\"ERROR: Expected 100, got {total_combinations}\"\n","assert len(HYPERPARAMETER_GRID['learning_rate']) == 5, f\"ERROR: LR should be 5, got {len(HYPERPARAMETER_GRID['learning_rate'])}\"\n","assert len(set(HYPERPARAMETER_GRID['learning_rate'])) == 5, \"ERROR: LR has DUPLICATES!\"\n","\n","print(f\"‚úÖ Round 2: Refined Hyperparameter Search (VALIDATED)\")\n","print(f\"   Total combinations: {total_combinations}\")\n","print(f\"   LR values ({len(HYPERPARAMETER_GRID['learning_rate'])}): {HYPERPARAMETER_GRID['learning_rate']}\")\n","print(f\"   WD values ({len(HYPERPARAMETER_GRID['weight_decay'])}): {HYPERPARAMETER_GRID['weight_decay']}\")\n","print(f\"   DR values ({len(HYPERPARAMETER_GRID['dropout'])}): {HYPERPARAMETER_GRID['dropout']}\")\n","print(f\"   Mixed Precision: {FIXED_PARAMS['use_amp']}\")\n","print(f\"   Batch size (FIXED): {HYPERPARAMETER_GRID['batch_size'][0]}\")"]},{"cell_type":"markdown","metadata":{"id":"IT3D0jLq7O6b"},"source":["## 3. Dataset Class"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWYFs6b-7O6b","outputId":"a3028ef9-a6d1-4613-a5d8-71494cca9b59","executionInfo":{"status":"ok","timestamp":1766500890019,"user_tz":-180,"elapsed":18,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Dataset class defined\n"]}],"source":["class PlayerDirectionDataset(Dataset):\n","    def __init__(self, root_dir, split='train', transform=None):\n","        if split == 'val':\n","            split = 'valid'\n","\n","        self.root_dir = Path(root_dir) / split\n","        self.transform = transform\n","\n","        labels_file = self.root_dir / 'labels.json'\n","        with open(labels_file, 'r') as f:\n","            labels_list = json.load(f)\n","\n","        self.labels = {item['filename']: item['direction_degree'] for item in labels_list}\n","        self.image_files = list(self.labels.keys())\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.image_files[idx]\n","        img_path = self.root_dir / 'images' / img_name\n","\n","        image = Image.open(img_path).convert('RGB')\n","        angle_deg = self.labels[img_name]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        angle_rad = math.radians(angle_deg)\n","\n","        return {\n","            'image': image,\n","            'sin': torch.tensor(math.sin(angle_rad), dtype=torch.float32),\n","            'cos': torch.tensor(math.cos(angle_rad), dtype=torch.float32),\n","            'angle_deg': torch.tensor(angle_deg, dtype=torch.float32)\n","        }\n","\n","print(\"‚úÖ Dataset class defined\")"]},{"cell_type":"markdown","metadata":{"id":"LTJc-xhP7O6c"},"source":["## 4. Model Architecture"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPd2yf4d7O6c","outputId":"5378e613-f873-447a-9d51-c2a9626cd52b","executionInfo":{"status":"ok","timestamp":1766500890038,"user_tz":-180,"elapsed":18,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Model architecture defined\n"]}],"source":["class PlayerDirectionPredictor(nn.Module):\n","    def __init__(self, dropout=0.5):\n","        super().__init__()\n","\n","        resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n","        self.features = nn.Sequential(*list(resnet.children())[:-1])\n","\n","        self.head = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(128, 2)\n","        )\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        sin_cos = self.head(features)\n","        sin_cos = nn.functional.normalize(sin_cos, p=2, dim=1)\n","        return sin_cos\n","\n","    def predict_angle(self, x):\n","        sin_cos = self.forward(x)\n","        angle_rad = torch.atan2(sin_cos[:, 0], sin_cos[:, 1])\n","        angle_deg = torch.rad2deg(angle_rad) % 360\n","        return angle_deg\n","\n","class CircularLoss(nn.Module):\n","    def forward(self, pred, target_sin, target_cos):\n","        pred_sin, pred_cos = pred[:, 0], pred[:, 1]\n","        loss = 1 - (pred_sin * target_sin + pred_cos * target_cos)\n","        return loss.mean()\n","\n","print(\"‚úÖ Model architecture defined\")"]},{"cell_type":"markdown","metadata":{"id":"vZG7enQi7O6c"},"source":["## 5. Training Functions with Mixed Precision"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4z6nMNmL7O6c","outputId":"d718d77f-c985-4c60-ab5b-d648aa6f1658","executionInfo":{"status":"ok","timestamp":1766500890231,"user_tz":-180,"elapsed":192,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Training functions defined with mixed precision\n"]}],"source":["def calculate_accuracy_metrics(pred_angles, target_angles, thresholds=[15, 30, 45]):\n","    \"\"\"Calculate accuracy at different angle thresholds\"\"\"\n","    errors = torch.abs(pred_angles - target_angles)\n","    # Handle circular nature (e.g., 359¬∞ and 1¬∞ are close)\n","    errors = torch.min(errors, 360 - errors)\n","\n","    metrics = {}\n","    for threshold in thresholds:\n","        acc = (errors <= threshold).float().mean().item() * 100\n","        metrics[f'acc{threshold}'] = acc\n","\n","    return metrics\n","\n","def train_epoch(model, loader, criterion, optimizer, device, use_amp=True, accumulation_steps=1):\n","    \"\"\"Train one epoch with mixed precision and gradient accumulation\"\"\"\n","    model.train()\n","    total_loss = 0\n","    all_pred_angles = []\n","    all_target_angles = []\n","\n","    scaler = GradScaler(enabled=use_amp)\n","    optimizer.zero_grad()\n","\n","    for batch_idx, batch in enumerate(loader):\n","        images = batch['image'].to(device)\n","        target_sin = batch['sin'].to(device)\n","        target_cos = batch['cos'].to(device)\n","        target_angles = batch['angle_deg'].to(device)\n","\n","        # Mixed precision forward pass\n","        with autocast(enabled=use_amp):\n","            pred = model(images)\n","            loss = criterion(pred, target_sin, target_cos)\n","            # Scale loss for gradient accumulation\n","            loss = loss / accumulation_steps\n","\n","        # Backward pass with gradient scaling\n","        scaler.scale(loss).backward()\n","\n","        # Update weights every accumulation_steps\n","        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(loader):\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        # Calculate metrics\n","        with torch.no_grad():\n","            pred_angles = model.predict_angle(images)\n","            all_pred_angles.append(pred_angles)\n","            all_target_angles.append(target_angles)\n","\n","        total_loss += loss.item() * accumulation_steps\n","\n","    all_pred_angles = torch.cat(all_pred_angles)\n","    all_target_angles = torch.cat(all_target_angles)\n","\n","    mae = torch.mean(torch.abs(all_pred_angles - all_target_angles)).item()\n","    metrics = calculate_accuracy_metrics(all_pred_angles, all_target_angles)\n","\n","    return total_loss / len(loader), mae, metrics\n","\n","def validate(model, loader, criterion, device, use_amp=True):\n","    \"\"\"Validate with mixed precision\"\"\"\n","    model.eval()\n","    total_loss = 0\n","    all_pred_angles = []\n","    all_target_angles = []\n","\n","    with torch.no_grad():\n","        for batch in loader:\n","            images = batch['image'].to(device)\n","            target_sin = batch['sin'].to(device)\n","            target_cos = batch['cos'].to(device)\n","            target_angles = batch['angle_deg'].to(device)\n","\n","            with autocast(enabled=use_amp):\n","                pred = model(images)\n","                loss = criterion(pred, target_sin, target_cos)\n","\n","            pred_angles = model.predict_angle(images)\n","            all_pred_angles.append(pred_angles)\n","            all_target_angles.append(target_angles)\n","\n","            total_loss += loss.item()\n","\n","    all_pred_angles = torch.cat(all_pred_angles)\n","    all_target_angles = torch.cat(all_target_angles)\n","\n","    mae = torch.mean(torch.abs(all_pred_angles - all_target_angles)).item()\n","    metrics = calculate_accuracy_metrics(all_pred_angles, all_target_angles)\n","\n","    return total_loss / len(loader), mae, metrics\n","\n","print(\"‚úÖ Training functions defined with mixed precision\")"]},{"cell_type":"markdown","metadata":{"id":"a4-PRNiQ7O6d"},"source":["## 6. Experiment Management"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Vnp2J67O6d","outputId":"c581489f-d5c8-4bf1-f356-ed90c393ebec","executionInfo":{"status":"ok","timestamp":1766500890245,"user_tz":-180,"elapsed":15,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Experiment management functions defined\n","‚úÖ Test: lr0p00015_bs32_wd0p0001_dr0p55\n","‚úÖ Naming verified!\n"]}],"source":["def get_experiment_name(params):\n","    \"\"\"Generate unique experiment name from parameters\"\"\"\n","    lr = params['learning_rate']\n","    wd = params['weight_decay']\n","    dr = params['dropout']\n","    bs = params['batch_size']\n","\n","    # Use decimal notation with 'p' instead of '.'\n","    # This ensures uniqueness and readability\n","    lr_str = f\"{lr:.5f}\".replace('.', 'p').rstrip('0')  # 0.00015 ‚Üí 0p00015\n","    wd_str = f\"{wd:.5f}\".replace('.', 'p').rstrip('0') if wd > 0 else \"0\"\n","    dr_str = f\"{dr:.2f}\".replace('.', 'p')  # 0.55 ‚Üí 0p55\n","\n","    return f\"lr{lr_str}_bs{bs}_wd{wd_str}_dr{dr_str}\"\n","\n","def check_if_completed(results_dir, exp_name):\n","    \"\"\"Check if experiment was already completed\"\"\"\n","    exp_dir = Path(results_dir) / exp_name\n","    if not exp_dir.exists():\n","        return False\n","\n","    result_file = exp_dir / 'result.json'\n","    if result_file.exists():\n","        with open(result_file, 'r') as f:\n","            result = json.load(f)\n","        return result.get('completed', False)\n","\n","    return False\n","\n","def save_results_to_excel(results_dir, all_results):\n","    \"\"\"Save all results to Excel file\"\"\"\n","    excel_file = Path(results_dir) / 'hyperparameter_tuning_results.xlsx'\n","\n","    flattened_results = []\n","    for result in all_results:\n","        flat_result = {\n","            'experiment_name': result['experiment_name'],\n","            'learning_rate': result['params']['learning_rate'],\n","            'batch_size': result['params']['batch_size'],\n","            'weight_decay': result['params']['weight_decay'],\n","            'dropout': result['params']['dropout'],\n","            'best_val_mae': result['best_val_mae'],\n","            'best_val_acc15': result['best_val_acc15'],\n","            'best_val_acc30': result['best_val_acc30'],\n","            'best_val_acc45': result['best_val_acc45'],\n","            'total_epochs': result['total_epochs'],\n","            'training_time_hours': result['training_time_hours'],\n","            'timestamp': result['timestamp']\n","        }\n","        flattened_results.append(flat_result)\n","\n","    df = pd.DataFrame(flattened_results)\n","    df = df.sort_values('best_val_mae')\n","\n","    df.to_excel(excel_file, index=False, engine='openpyxl')\n","    print(f\"\\nüìä Results saved to: {excel_file}\")\n","\n","    return excel_file\n","\n","print(\"‚úÖ Experiment management functions defined\")\n","\n","# TEST\n","test_params = {\n","    'learning_rate': 1.5e-04,\n","    'batch_size': 32,\n","    'weight_decay': 1e-04,\n","    'dropout': 0.55\n","}\n","test_name = get_experiment_name(test_params)\n","print(f\"‚úÖ Test: {test_name}\")\n","assert \"0p00015\" in test_name, \"LR naming failed!\"\n","print(\"‚úÖ Naming verified!\")"]},{"cell_type":"markdown","metadata":{"id":"validation_header"},"source":["## 6.5. üîç Validate Grid (Check for Duplicates)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"validation_code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766500890366,"user_tz":-180,"elapsed":69,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"76d196bd-748d-4225-f421-133e603cd37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Validating hyperparameter grid...\n","======================================================================\n","‚úÖ Total combinations: 100\n","‚úÖ LR values: [0.00015, 0.00018, 0.0002, 0.00022, 0.00025]\n","Checking HYPERPARAMETER_GRID...\n","learning_rate: [0.00015, 0.00018, 0.0002, 0.00022, 0.00025]\n","  Length: 5\n","  Unique: 5\n","\n","‚úÖ No duplicates in grid\n"]}],"source":["# Validate hyperparameter grid\n","from collections import Counter\n","\n","print(\"üîç Validating hyperparameter grid...\")\n","print(\"=\" * 70)\n","\n","param_combinations_test = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","print(f\"‚úÖ Total combinations: {len(param_combinations_test)}\")\n","print(f\"‚úÖ LR values: {sorted(set([x[0] for x in param_combinations_test]))}\")\n","\n","exp_names = []\n","for lr, bs, wd, dropout in param_combinations_test:\n","    params = {'learning_rate': lr, 'batch_size': bs, 'weight_decay': wd, 'dropout': dropout}\n","    exp_name = get_experiment_name(params)\n","    exp_names.append(exp_name)\n","\n","name_counts = Counter(exp_names)\n","duplicates = {name: count for name, count in name_counts.items() if count > 1}\n","# Debug: Check what's actually in your grid\n","print(\"Checking HYPERPARAMETER_GRID...\")\n","print(f\"learning_rate: {HYPERPARAMETER_GRID['learning_rate']}\")\n","print(f\"  Length: {len(HYPERPARAMETER_GRID['learning_rate'])}\")\n","print(f\"  Unique: {len(set(HYPERPARAMETER_GRID['learning_rate']))}\")\n","\n","# Check if any value appears more than once\n","from collections import Counter\n","lr_counts = Counter(HYPERPARAMETER_GRID['learning_rate'])\n","duplicates = {lr: count for lr, count in lr_counts.items() if count > 1}\n","if duplicates:\n","    print(f\"\\n‚ùå DUPLICATES IN GRID:\")\n","    for lr, count in duplicates.items():\n","        print(f\"   {lr:.0e} appears {count} times\")\n","else:\n","    print(f\"\\n‚úÖ No duplicates in grid\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cleanup_header"},"source":["## 6.6. üßπ Cleanup Duplicates (Run Once Before Training)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cleanup_code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766500935198,"user_tz":-180,"elapsed":44830,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"0f752342-69ad-4832-e153-dcc655870661"},"outputs":[{"output_type":"stream","name":"stdout","text":["üßπ CLEANING UP DUPLICATES\n","======================================================================\n","\n","üìä Step 1: Cleaning Excel...\n","   Original: 78 experiments\n","   Found 38 duplicates, removing...\n","   ‚úÖ Cleaned: 40 unique experiments\n","\n","üìÅ Step 2: Cleaning folders...\n","   Found 101 folders\n","   Config 2e-04_32_0e+00_0.60: 3 folders\n","      Keep:   lr0p00018_bs32_wd0_dr0p60 (MAE=57.90¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0_dr0p60 (MAE=59.23¬∞)\n","      Remove: lr0p00022_bs32_wd0_dr0p60 (MAE=63.17¬∞)\n","   Config 2e-04_32_5e-05_0.50: 3 folders\n","      Remove: lr0p00018_bs32_wd0p00005_dr0p50 (MAE=62.76¬∞)\n","      Keep:   lr0p0002_bs32_wd0p00005_dr0p50 (MAE=57.88¬∞) ‚≠ê\n","      Remove: lr0p00022_bs32_wd0p00005_dr0p50 (MAE=59.94¬∞)\n","   Config 2e-04_32_5e-05_0.60: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p00005_dr0p60 (MAE=58.61¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p00005_dr0p60 (MAE=60.79¬∞)\n","      Remove: lr0p00022_bs32_wd0p00005_dr0p60 (MAE=65.42¬∞)\n","   Config 2e-04_32_1e-04_0.50: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0001_dr0p50 (MAE=59.22¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0001_dr0p50 (MAE=59.41¬∞)\n","      Remove: lr0p00022_bs32_wd0p0001_dr0p50 (MAE=66.18¬∞)\n","   Config 2e-04_32_1e-04_0.55: 3 folders\n","      Remove: lr0p00018_bs32_wd0p0001_dr0p55 (MAE=59.70¬∞)\n","      Keep:   lr0p0002_bs32_wd0p0001_dr0p55 (MAE=57.18¬∞) ‚≠ê\n","      Remove: lr0p00022_bs32_wd0p0001_dr0p55 (MAE=58.25¬∞)\n","   Config 2e-04_32_1e-04_0.65: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0001_dr0p65 (MAE=60.36¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0001_dr0p65 (MAE=65.59¬∞)\n","      Remove: lr0p00022_bs32_wd0p0001_dr0p65 (MAE=61.78¬∞)\n","   Config 2e-04_32_2e-04_0.50: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0002_dr0p50 (MAE=59.79¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0002_dr0p50 (MAE=62.80¬∞)\n","      Remove: lr0p00022_bs32_wd0p0002_dr0p50 (MAE=64.02¬∞)\n","   Config 2e-04_32_2e-04_0.55: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0002_dr0p55 (MAE=60.35¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0002_dr0p55 (MAE=67.08¬∞)\n","      Remove: lr0p00022_bs32_wd0p0002_dr0p55 (MAE=66.35¬∞)\n","   Config 2e-04_32_2e-04_0.60: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0002_dr0p60 (MAE=59.16¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0002_dr0p60 (MAE=62.73¬∞)\n","      Remove: lr0p00022_bs32_wd0p0002_dr0p60 (MAE=61.73¬∞)\n","   Config 2e-04_32_2e-04_0.65: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0002_dr0p65 (MAE=54.77¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0002_dr0p65 (MAE=58.69¬∞)\n","      Remove: lr0p00022_bs32_wd0p0002_dr0p65 (MAE=61.75¬∞)\n","   Config 2e-04_32_5e-04_0.55: 3 folders\n","      Remove: lr0p00018_bs32_wd0p0005_dr0p55 (MAE=61.54¬∞)\n","      Keep:   lr0p0002_bs32_wd0p0005_dr0p55 (MAE=58.64¬∞) ‚≠ê\n","      Remove: lr0p00022_bs32_wd0p0005_dr0p55 (MAE=59.01¬∞)\n","   Config 2e-04_32_5e-04_0.65: 2 folders\n","      Remove: lr0p00018_bs32_wd0p0005_dr0p65 (MAE=69.43¬∞)\n","      Keep:   lr0p0002_bs32_wd0p0005_dr0p65 (MAE=64.05¬∞) ‚≠ê\n","   Config 2e-04_32_0e+00_0.50: 3 folders\n","      Keep:   lr0p00018_bs32_wd0_dr0p50 (MAE=58.73¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0_dr0p50 (MAE=65.61¬∞)\n","      Remove: lr0p00022_bs32_wd0_dr0p50 (MAE=59.12¬∞)\n","   Config 2e-04_32_0e+00_0.55: 3 folders\n","      Keep:   lr0p00018_bs32_wd0_dr0p55 (MAE=58.18¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0_dr0p55 (MAE=66.07¬∞)\n","      Remove: lr0p00022_bs32_wd0_dr0p55 (MAE=67.57¬∞)\n","   Config 2e-04_32_0e+00_0.65: 3 folders\n","      Remove: lr0p00018_bs32_wd0_dr0p65 (MAE=62.71¬∞)\n","      Remove: lr0p0002_bs32_wd0_dr0p65 (MAE=63.18¬∞)\n","      Keep:   lr0p00022_bs32_wd0_dr0p65 (MAE=59.21¬∞) ‚≠ê\n","   Config 2e-04_32_5e-05_0.55: 3 folders\n","      Remove: lr0p00018_bs32_wd0p00005_dr0p55 (MAE=62.36¬∞)\n","      Keep:   lr0p0002_bs32_wd0p00005_dr0p55 (MAE=58.43¬∞) ‚≠ê\n","      Remove: lr0p00022_bs32_wd0p00005_dr0p55 (MAE=65.12¬∞)\n","   Config 2e-04_32_5e-05_0.65: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p00005_dr0p65 (MAE=59.94¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p00005_dr0p65 (MAE=61.56¬∞)\n","      Remove: lr0p00022_bs32_wd0p00005_dr0p65 (MAE=66.00¬∞)\n","   Config 2e-04_32_1e-04_0.60: 3 folders\n","      Remove: lr0p00018_bs32_wd0p0001_dr0p60 (MAE=57.73¬∞)\n","      Remove: lr0p0002_bs32_wd0p0001_dr0p60 (MAE=64.01¬∞)\n","      Keep:   lr0p00022_bs32_wd0p0001_dr0p60 (MAE=57.01¬∞) ‚≠ê\n","   Config 2e-04_32_5e-04_0.50: 3 folders\n","      Keep:   lr0p00018_bs32_wd0p0005_dr0p50 (MAE=60.28¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0005_dr0p50 (MAE=63.14¬∞)\n","      Remove: lr0p00022_bs32_wd0p0005_dr0p50 (MAE=67.57¬∞)\n","   Config 2e-04_32_5e-04_0.60: 2 folders\n","      Keep:   lr0p00018_bs32_wd0p0005_dr0p60 (MAE=53.30¬∞) ‚≠ê\n","      Remove: lr0p0002_bs32_wd0p0005_dr0p60 (MAE=57.54¬∞)\n","\n","   Removing 38 duplicate folders...\n","   ‚úÖ Removed 38 folders\n","\n","======================================================================\n","‚úÖ CLEANUP COMPLETE!\n","======================================================================\n"]}],"source":["# Clean up duplicate experiments from folder and Excel\n","import shutil\n","from collections import defaultdict\n","\n","print(\"üßπ CLEANING UP DUPLICATES\")\n","print(\"=\" * 70)\n","\n","results_dir = Path(BASE_CONFIG['results_dir'])\n","excel_file = results_dir / 'hyperparameter_tuning_results.xlsx'\n","\n","# Step 1: Clean Excel\n","print(\"\\nüìä Step 1: Cleaning Excel...\")\n","if excel_file.exists():\n","    df = pd.read_excel(excel_file)\n","    print(f\"   Original: {len(df)} experiments\")\n","\n","    df['config'] = df.apply(\n","        lambda x: f\"{x['learning_rate']:.0e}_{x['batch_size']}_{x['weight_decay']:.0e}_{x['dropout']:.2f}\",\n","        axis=1\n","    )\n","\n","    duplicates = df[df.duplicated(subset='config', keep='first')]\n","\n","    if len(duplicates) > 0:\n","        print(f\"   Found {len(duplicates)} duplicates, removing...\")\n","        shutil.copy(excel_file, results_dir / 'results_BACKUP.xlsx')\n","        df_clean = df.drop_duplicates(subset='config', keep='first').drop(columns=['config'])\n","        df_clean.to_excel(excel_file, index=False, engine='openpyxl')\n","        print(f\"   ‚úÖ Cleaned: {len(df_clean)} unique experiments\")\n","    else:\n","        print(f\"   ‚úÖ No duplicates in Excel\")\n","else:\n","    print(f\"   ‚ö†Ô∏è  Excel not found\")\n","\n","# Step 2: Clean folders\n","print(\"\\nüìÅ Step 2: Cleaning folders...\")\n","if results_dir.exists():\n","    folders = [d for d in results_dir.iterdir() if d.is_dir()]\n","    print(f\"   Found {len(folders)} folders\")\n","\n","    experiments_by_config = defaultdict(list)\n","\n","    for folder in folders:\n","        result_file = folder / 'result.json'\n","        if result_file.exists():\n","            with open(result_file, 'r') as f:\n","                result = json.load(f)\n","                p = result['params']\n","                key = f\"{p['learning_rate']:.0e}_{p['batch_size']}_{p['weight_decay']:.0e}_{p['dropout']:.2f}\"\n","                experiments_by_config[key].append({\n","                    'folder': folder,\n","                    'mae': result['best_val_mae']\n","                })\n","\n","    to_remove = []\n","    for key, exps in experiments_by_config.items():\n","        if len(exps) > 1:\n","            print(f\"   Config {key}: {len(exps)} folders\")\n","            best = min(exps, key=lambda x: x['mae'])\n","            for exp in exps:\n","                if exp != best:\n","                    print(f\"      Remove: {exp['folder'].name} (MAE={exp['mae']:.2f}¬∞)\")\n","                    to_remove.append(exp['folder'])\n","                else:\n","                    print(f\"      Keep:   {exp['folder'].name} (MAE={exp['mae']:.2f}¬∞) ‚≠ê\")\n","\n","    if to_remove:\n","        print(f\"\\n   Removing {len(to_remove)} duplicate folders...\")\n","        for folder in to_remove:\n","            shutil.rmtree(folder)\n","        print(f\"   ‚úÖ Removed {len(to_remove)} folders\")\n","    else:\n","        print(f\"   ‚úÖ No duplicate folders\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"‚úÖ CLEANUP COMPLETE!\")\n","print(\"=\" * 70)"]},{"cell_type":"markdown","metadata":{"id":"uCv7IWsS7O6d"},"source":["## 7. Main Training Loop"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxP8YvTS7O6e","outputId":"f5626704-008a-4f17-a576-3dcbc8ae33fa","executionInfo":{"status":"ok","timestamp":1766500935260,"user_tz":-180,"elapsed":55,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Main training loop defined\n"]}],"source":["def train_single_experiment(params, train_loader, val_loader, device, results_dir):\n","    \"\"\"Train a single hyperparameter configuration\"\"\"\n","\n","    exp_name = get_experiment_name(params)\n","    exp_dir = Path(results_dir) / exp_name\n","    exp_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # Initialize model\n","    model = PlayerDirectionPredictor(dropout=params['dropout']).to(device)\n","    criterion = CircularLoss()\n","    optimizer = optim.AdamW(\n","        model.parameters(),\n","        lr=params['learning_rate'],\n","        weight_decay=params['weight_decay']\n","    )\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7\n","    )\n","\n","    best_val_mae = float('inf')\n","    best_val_acc15 = 0\n","    best_val_acc30 = 0\n","    best_val_acc45 = 0\n","    patience_counter = 0\n","    history = []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(FIXED_PARAMS['num_epochs']):\n","        # Train\n","        train_loss, train_mae, train_metrics = train_epoch(\n","            model, train_loader, criterion, optimizer, device,\n","            use_amp=FIXED_PARAMS['use_amp'],\n","            accumulation_steps=FIXED_PARAMS['gradient_accumulation_steps']\n","        )\n","\n","        # Validate\n","        val_loss, val_mae, val_metrics = validate(\n","            model, val_loader, criterion, device,\n","            use_amp=FIXED_PARAMS['use_amp']\n","        )\n","\n","        # Update scheduler\n","        scheduler.step(val_mae)\n","\n","        # Save history\n","        epoch_data = {\n","            'epoch': epoch + 1,\n","            'train_loss': train_loss,\n","            'train_mae': train_mae,\n","            'train_acc15': train_metrics['acc15'],\n","            'train_acc30': train_metrics['acc30'],\n","            'train_acc45': train_metrics['acc45'],\n","            'val_loss': val_loss,\n","            'val_mae': val_mae,\n","            'val_acc15': val_metrics['acc15'],\n","            'val_acc30': val_metrics['acc30'],\n","            'val_acc45': val_metrics['acc45'],\n","            'lr': optimizer.param_groups[0]['lr']\n","        }\n","        history.append(epoch_data)\n","\n","        # Track best metrics\n","        if val_metrics['acc15'] > best_val_acc15:\n","            best_val_acc15 = val_metrics['acc15']\n","        if val_metrics['acc30'] > best_val_acc30:\n","            best_val_acc30 = val_metrics['acc30']\n","        if val_metrics['acc45'] > best_val_acc45:\n","            best_val_acc45 = val_metrics['acc45']\n","\n","        # Check for improvement\n","        if val_mae < best_val_mae - FIXED_PARAMS['early_stopping_min_delta']:\n","            best_val_mae = val_mae\n","            patience_counter = 0\n","\n","            # Save best model\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'val_mae': val_mae,\n","                'val_metrics': val_metrics,\n","                'params': params\n","            }, exp_dir / 'best_model.pth')\n","        else:\n","            patience_counter += 1\n","\n","        # Early stopping\n","        if patience_counter >= FIXED_PARAMS['early_stopping_patience']:\n","            break\n","\n","    training_time = (time.time() - start_time) / 3600\n","\n","    # Save history\n","    with open(exp_dir / 'history.json', 'w') as f:\n","        json.dump(history, f, indent=2)\n","\n","    # Save final result\n","    result = {\n","        'experiment_name': exp_name,\n","        'params': params,\n","        'best_val_mae': best_val_mae,\n","        'best_val_acc15': best_val_acc15,\n","        'best_val_acc30': best_val_acc30,\n","        'best_val_acc45': best_val_acc45,\n","        'total_epochs': len(history),\n","        'training_time_hours': training_time,\n","        'completed': True,\n","        'timestamp': datetime.now().isoformat()\n","    }\n","\n","    with open(exp_dir / 'result.json', 'w') as f:\n","        json.dump(result, f, indent=2)\n","\n","    return result\n","\n","print(\"‚úÖ Main training loop defined\")"]},{"cell_type":"markdown","metadata":{"id":"do1yQ4rx7O6e"},"source":["## 8. Test Maximum Batch Size (Optional)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y06DHSIZ7O6e","outputId":"808da90d-4518-46e4-9c4d-7eb1b10d75d6","executionInfo":{"status":"ok","timestamp":1766500947438,"user_tz":-180,"elapsed":12176,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Testing maximum batch size for your GPU...\n","\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 133MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Batch size  32: OK (GPU: 0.3 GB)\n","‚úÖ Batch size  64: OK (GPU: 0.6 GB)\n","‚úÖ Batch size  96: OK (GPU: 0.8 GB)\n","‚úÖ Batch size 128: OK (GPU: 1.0 GB)\n","‚úÖ Batch size 192: OK (GPU: 1.5 GB)\n","‚úÖ Batch size 256: OK (GPU: 2.0 GB)\n","‚úÖ Batch size 320: OK (GPU: 2.5 GB)\n","‚úÖ Batch size 384: OK (GPU: 2.9 GB)\n","‚úÖ Batch size 448: OK (GPU: 3.4 GB)\n","‚úÖ Batch size 512: OK (GPU: 3.9 GB)\n","\n","üéØ Maximum batch size: 512\n","üí° Your hyperparameter grid includes: [32]\n","   All batch sizes should work fine!\n"]}],"source":["print(\"üîç Testing maximum batch size for your GPU...\\n\")\n","\n","test_sizes = [32, 64, 96, 128, 192, 256, 320, 384, 448, 512]\n","max_batch_size = 32\n","\n","for bs in test_sizes:\n","    try:\n","        model = PlayerDirectionPredictor(dropout=0.5).to(device)\n","        test_batch = torch.randn(bs, 3, 224, 224).to(device)\n","\n","        with torch.no_grad():\n","            _ = model(test_batch)\n","\n","        max_batch_size = bs\n","        gpu_memory = torch.cuda.max_memory_allocated() / 1e9\n","        print(f\"‚úÖ Batch size {bs:3d}: OK (GPU: {gpu_memory:.1f} GB)\")\n","\n","        del model, test_batch\n","        torch.cuda.empty_cache()\n","\n","    except RuntimeError as e:\n","        if \"out of memory\" in str(e):\n","            print(f\"‚ùå Batch size {bs:3d}: Out of memory\")\n","            break\n","        raise e\n","\n","print(f\"\\nüéØ Maximum batch size: {max_batch_size}\")\n","print(f\"üí° Your hyperparameter grid includes: {HYPERPARAMETER_GRID['batch_size']}\")\n","print(f\"   All batch sizes should work fine!\")"]},{"cell_type":"markdown","metadata":{"id":"i6Qgi9hp7O6e"},"source":["## 9. Load Data (Once)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNjs5D_m7O6e","outputId":"98e01daf-f37d-4343-a7ad-b21462329c33","executionInfo":{"status":"ok","timestamp":1766500948694,"user_tz":-180,"elapsed":1254,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üìÇ LOADING DATASETS\n","======================================================================\n","\n","‚úÖ Train: 1400 images\n","‚úÖ Val: 300 images\n","======================================================================\n"]}],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üìÇ LOADING DATASETS\")\n","print(\"=\"*70)\n","\n","# Data transforms\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load datasets\n","train_dataset = PlayerDirectionDataset(BASE_CONFIG['data_root'], 'train', train_transform)\n","val_dataset = PlayerDirectionDataset(BASE_CONFIG['data_root'], 'val', val_transform)\n","\n","print(f\"\\n‚úÖ Train: {len(train_dataset)} images\")\n","print(f\"‚úÖ Val: {len(val_dataset)} images\")\n","print(\"=\"*70)"]},{"cell_type":"code","source":["from pathlib import Path\n","import json\n","import shutil\n","\n","results_dir = Path('/content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed')\n","\n","print(\"üîÑ RENAMING EXISTING FOLDERS TO NEW FORMAT\")\n","print(\"=\" * 70)\n","\n","folders = [d for d in results_dir.iterdir() if d.is_dir()]\n","renamed_count = 0\n","\n","for folder in folders:\n","    result_file = folder / 'result.json'\n","    if result_file.exists():\n","        try:\n","            # Read the actual parameters\n","            with open(result_file, 'r') as f:\n","                result = json.load(f)\n","\n","            params = result['params']\n","\n","            # Generate the NEW correct name\n","            new_name = get_experiment_name(params)\n","            new_path = results_dir / new_name\n","\n","            # Check if rename is needed\n","            if folder.name != new_name:\n","                print(f\"\\n  Rename:\")\n","                print(f\"    From: {folder.name}\")\n","                print(f\"    To:   {new_name}\")\n","\n","                # Rename\n","                folder.rename(new_path)\n","                renamed_count += 1\n","        except Exception as e:\n","            print(f\"  ‚ö†Ô∏è  Error with {folder.name}: {e}\")\n","\n","print(f\"\\n{'=' * 70}\")\n","print(f\"‚úÖ Renamed {renamed_count} folders\")\n","print(f\"{'=' * 70}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJMICseX5BEu","executionInfo":{"status":"ok","timestamp":1766500948808,"user_tz":-180,"elapsed":115,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"outputId":"b241f7e6-b42f-469d-da6f-1fd60e2aec9e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ RENAMING EXISTING FOLDERS TO NEW FORMAT\n","======================================================================\n","\n","======================================================================\n","‚úÖ Renamed 0 folders\n","======================================================================\n"]}]},{"cell_type":"markdown","metadata":{"id":"vc3GlJ6X7O6e"},"source":["## 10. Run Hyperparameter Tuning"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz2nmIgW7O6f","outputId":"4250b6e6-9c7d-48ff-d2b5-0b0305d50870","executionInfo":{"status":"ok","timestamp":1766529316373,"user_tz":-180,"elapsed":28005556,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Checking for duplicate experiment names...\n","‚úÖ All 100 experiment names are unique!\n","\n","üìä First 5 experiment names:\n","   1. lr0p00015_bs32_wd0_dr0p50\n","   2. lr0p00015_bs32_wd0_dr0p55\n","   3. lr0p00015_bs32_wd0_dr0p60\n","   4. lr0p00015_bs32_wd0_dr0p65\n","   5. lr0p00015_bs32_wd0p00005_dr0p50\n","\n","üìä Last 5 experiment names:\n","   96. lr0p00025_bs32_wd0p0002_dr0p65\n","   97. lr0p00025_bs32_wd0p0005_dr0p50\n","   98. lr0p00025_bs32_wd0p0005_dr0p55\n","   99. lr0p00025_bs32_wd0p0005_dr0p60\n","   100. lr0p00025_bs32_wd0p0005_dr0p65\n","\n","======================================================================\n","üöÄ STARTING HYPERPARAMETER TUNING\n","======================================================================\n","\n","üìä Total combinations to test: 100\n","‚öôÔ∏è  Mixed Precision: True\n","‚öôÔ∏è  Gradient Accumulation: 2x\n","\n","======================================================================\n","üîß Experiment 1/100: lr0p00015_bs32_wd0_dr0p50\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 0e+00, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 2/100: lr0p00015_bs32_wd0_dr0p55\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 0e+00, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 3/100: lr0p00015_bs32_wd0_dr0p60\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 0e+00, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 4/100: lr0p00015_bs32_wd0_dr0p65\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 0e+00, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 5/100: lr0p00015_bs32_wd0p00005_dr0p50\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-05, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 6/100: lr0p00015_bs32_wd0p00005_dr0p55\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-05, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 7/100: lr0p00015_bs32_wd0p00005_dr0p60\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-05, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 8/100: lr0p00015_bs32_wd0p00005_dr0p65\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-05, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 9/100: lr0p00015_bs32_wd0p0001_dr0p50\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 10/100: lr0p00015_bs32_wd0p0001_dr0p55\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 11/100: lr0p00015_bs32_wd0p0001_dr0p60\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 12/100: lr0p00015_bs32_wd0p0001_dr0p65\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 1e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 13/100: lr0p00015_bs32_wd0p0002_dr0p50\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 2e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 14/100: lr0p00015_bs32_wd0p0002_dr0p55\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 2e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 15/100: lr0p00015_bs32_wd0p0002_dr0p60\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 2e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 16/100: lr0p00015_bs32_wd0p0002_dr0p65\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 2e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 17/100: lr0p00015_bs32_wd0p0005_dr0p50\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 18/100: lr0p00015_bs32_wd0p0005_dr0p55\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 19/100: lr0p00015_bs32_wd0p0005_dr0p60\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 20/100: lr0p00015_bs32_wd0p0005_dr0p65\n","======================================================================\n","   LR: 1e-04, Batch: 32, WD: 5e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 21/100: lr0p00018_bs32_wd0_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 22/100: lr0p00018_bs32_wd0_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 23/100: lr0p00018_bs32_wd0_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 24/100: lr0p00018_bs32_wd0_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.65\n","   Effective Batch: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4142847985.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler(enabled=use_amp)\n","/tmp/ipython-input-4142847985.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=use_amp):\n","/tmp/ipython-input-4142847985.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=use_amp):\n"]},{"output_type":"stream","name":"stdout","text":["\n","   ‚úÖ Best Val MAE: 66.63¬∞\n","   ‚úÖ Acc@15¬∞: 29.0%\n","   ‚úÖ Acc@30¬∞: 52.3%\n","   ‚úÖ Acc@45¬∞: 69.3%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 25/100: lr0p00018_bs32_wd0p00005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 62.24¬∞\n","   ‚úÖ Acc@15¬∞: 38.0%\n","   ‚úÖ Acc@30¬∞: 55.3%\n","   ‚úÖ Acc@45¬∞: 71.3%\n","   ‚è±Ô∏è  Time: 0.17 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 26/100: lr0p00018_bs32_wd0p00005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.82¬∞\n","   ‚úÖ Acc@15¬∞: 35.0%\n","   ‚úÖ Acc@30¬∞: 57.3%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.28 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 27/100: lr0p00018_bs32_wd0p00005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 28/100: lr0p00018_bs32_wd0p00005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 29/100: lr0p00018_bs32_wd0p0001_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 30/100: lr0p00018_bs32_wd0p0001_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.78¬∞\n","   ‚úÖ Acc@15¬∞: 33.0%\n","   ‚úÖ Acc@30¬∞: 59.0%\n","   ‚úÖ Acc@45¬∞: 75.3%\n","   ‚è±Ô∏è  Time: 0.21 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 31/100: lr0p00018_bs32_wd0p0001_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 62.13¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 53.7%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.14 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 32/100: lr0p00018_bs32_wd0p0001_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 33/100: lr0p00018_bs32_wd0p0002_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 34/100: lr0p00018_bs32_wd0p0002_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 35/100: lr0p00018_bs32_wd0p0002_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 36/100: lr0p00018_bs32_wd0p0002_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 37/100: lr0p00018_bs32_wd0p0005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 38/100: lr0p00018_bs32_wd0p0005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.97¬∞\n","   ‚úÖ Acc@15¬∞: 35.7%\n","   ‚úÖ Acc@30¬∞: 55.0%\n","   ‚úÖ Acc@45¬∞: 73.7%\n","   ‚è±Ô∏è  Time: 0.17 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 39/100: lr0p00018_bs32_wd0p0005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 40/100: lr0p00018_bs32_wd0p0005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 55.84¬∞\n","   ‚úÖ Acc@15¬∞: 34.7%\n","   ‚úÖ Acc@30¬∞: 60.7%\n","   ‚úÖ Acc@45¬∞: 77.7%\n","   ‚è±Ô∏è  Time: 0.20 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 41/100: lr0p0002_bs32_wd0_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 60.58¬∞\n","   ‚úÖ Acc@15¬∞: 34.0%\n","   ‚úÖ Acc@30¬∞: 54.7%\n","   ‚úÖ Acc@45¬∞: 74.0%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 42/100: lr0p0002_bs32_wd0_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 56.95¬∞\n","   ‚úÖ Acc@15¬∞: 36.0%\n","   ‚úÖ Acc@30¬∞: 57.7%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.22 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 43/100: lr0p0002_bs32_wd0_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 60.93¬∞\n","   ‚úÖ Acc@15¬∞: 34.0%\n","   ‚úÖ Acc@30¬∞: 56.3%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 44/100: lr0p0002_bs32_wd0_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 61.23¬∞\n","   ‚úÖ Acc@15¬∞: 32.0%\n","   ‚úÖ Acc@30¬∞: 56.0%\n","   ‚úÖ Acc@45¬∞: 72.7%\n","   ‚è±Ô∏è  Time: 0.20 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 45/100: lr0p0002_bs32_wd0p00005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 46/100: lr0p0002_bs32_wd0p00005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 47/100: lr0p0002_bs32_wd0p00005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 66.28¬∞\n","   ‚úÖ Acc@15¬∞: 31.0%\n","   ‚úÖ Acc@30¬∞: 54.7%\n","   ‚úÖ Acc@45¬∞: 71.3%\n","   ‚è±Ô∏è  Time: 0.16 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 48/100: lr0p0002_bs32_wd0p00005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.46¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 57.3%\n","   ‚úÖ Acc@45¬∞: 72.7%\n","   ‚è±Ô∏è  Time: 0.23 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 49/100: lr0p0002_bs32_wd0p0001_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.03¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 56.3%\n","   ‚úÖ Acc@45¬∞: 69.7%\n","   ‚è±Ô∏è  Time: 0.17 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 50/100: lr0p0002_bs32_wd0p0001_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 51/100: lr0p0002_bs32_wd0p0001_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 66.94¬∞\n","   ‚úÖ Acc@15¬∞: 33.0%\n","   ‚úÖ Acc@30¬∞: 54.0%\n","   ‚úÖ Acc@45¬∞: 70.0%\n","   ‚è±Ô∏è  Time: 0.24 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 52/100: lr0p0002_bs32_wd0p0001_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 57.41¬∞\n","   ‚úÖ Acc@15¬∞: 34.3%\n","   ‚úÖ Acc@30¬∞: 56.7%\n","   ‚úÖ Acc@45¬∞: 71.3%\n","   ‚è±Ô∏è  Time: 0.20 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 53/100: lr0p0002_bs32_wd0p0002_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 61.22¬∞\n","   ‚úÖ Acc@15¬∞: 33.0%\n","   ‚úÖ Acc@30¬∞: 57.7%\n","   ‚úÖ Acc@45¬∞: 71.0%\n","   ‚è±Ô∏è  Time: 0.22 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 54/100: lr0p0002_bs32_wd0p0002_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.08¬∞\n","   ‚úÖ Acc@15¬∞: 33.3%\n","   ‚úÖ Acc@30¬∞: 56.3%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 55/100: lr0p0002_bs32_wd0p0002_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 66.34¬∞\n","   ‚úÖ Acc@15¬∞: 35.7%\n","   ‚úÖ Acc@30¬∞: 55.0%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.16 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 56/100: lr0p0002_bs32_wd0p0002_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 56.19¬∞\n","   ‚úÖ Acc@15¬∞: 33.0%\n","   ‚úÖ Acc@30¬∞: 57.0%\n","   ‚úÖ Acc@45¬∞: 71.0%\n","   ‚è±Ô∏è  Time: 0.23 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 57/100: lr0p0002_bs32_wd0p0005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.61¬∞\n","   ‚úÖ Acc@15¬∞: 36.3%\n","   ‚úÖ Acc@30¬∞: 54.3%\n","   ‚úÖ Acc@45¬∞: 69.0%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 58/100: lr0p0002_bs32_wd0p0005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 59/100: lr0p0002_bs32_wd0p0005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 64.88¬∞\n","   ‚úÖ Acc@15¬∞: 36.0%\n","   ‚úÖ Acc@30¬∞: 56.0%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 60/100: lr0p0002_bs32_wd0p0005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 61/100: lr0p00022_bs32_wd0_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 61.33¬∞\n","   ‚úÖ Acc@15¬∞: 34.7%\n","   ‚úÖ Acc@30¬∞: 56.0%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.26 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 62/100: lr0p00022_bs32_wd0_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 60.99¬∞\n","   ‚úÖ Acc@15¬∞: 33.3%\n","   ‚úÖ Acc@30¬∞: 58.3%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.17 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 63/100: lr0p00022_bs32_wd0_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 60.85¬∞\n","   ‚úÖ Acc@15¬∞: 34.0%\n","   ‚úÖ Acc@30¬∞: 56.3%\n","   ‚úÖ Acc@45¬∞: 73.3%\n","   ‚è±Ô∏è  Time: 0.18 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 64/100: lr0p00022_bs32_wd0_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 0e+00, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 65/100: lr0p00022_bs32_wd0p00005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.46¬∞\n","   ‚úÖ Acc@15¬∞: 32.3%\n","   ‚úÖ Acc@30¬∞: 55.7%\n","   ‚úÖ Acc@45¬∞: 73.0%\n","   ‚è±Ô∏è  Time: 0.16 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 66/100: lr0p00022_bs32_wd0p00005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 62.90¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 58.3%\n","   ‚úÖ Acc@45¬∞: 72.7%\n","   ‚è±Ô∏è  Time: 0.21 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 67/100: lr0p00022_bs32_wd0p00005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 67.72¬∞\n","   ‚úÖ Acc@15¬∞: 33.0%\n","   ‚úÖ Acc@30¬∞: 52.7%\n","   ‚úÖ Acc@45¬∞: 69.0%\n","   ‚è±Ô∏è  Time: 0.24 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 68/100: lr0p00022_bs32_wd0p00005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-05, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.96¬∞\n","   ‚úÖ Acc@15¬∞: 32.7%\n","   ‚úÖ Acc@30¬∞: 53.0%\n","   ‚úÖ Acc@45¬∞: 70.7%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 69/100: lr0p00022_bs32_wd0p0001_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 59.66¬∞\n","   ‚úÖ Acc@15¬∞: 34.7%\n","   ‚úÖ Acc@30¬∞: 56.7%\n","   ‚úÖ Acc@45¬∞: 72.7%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 70/100: lr0p00022_bs32_wd0p0001_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.04¬∞\n","   ‚úÖ Acc@15¬∞: 36.0%\n","   ‚úÖ Acc@30¬∞: 57.7%\n","   ‚úÖ Acc@45¬∞: 74.0%\n","   ‚è±Ô∏è  Time: 0.18 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 71/100: lr0p00022_bs32_wd0p0001_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 72/100: lr0p00022_bs32_wd0p0001_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 1e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 62.55¬∞\n","   ‚úÖ Acc@15¬∞: 34.3%\n","   ‚úÖ Acc@30¬∞: 55.7%\n","   ‚úÖ Acc@45¬∞: 70.0%\n","   ‚è±Ô∏è  Time: 0.19 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 73/100: lr0p00022_bs32_wd0p0002_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 57.75¬∞\n","   ‚úÖ Acc@15¬∞: 34.0%\n","   ‚úÖ Acc@30¬∞: 55.3%\n","   ‚úÖ Acc@45¬∞: 72.7%\n","   ‚è±Ô∏è  Time: 0.24 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 74/100: lr0p00022_bs32_wd0p0002_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.53¬∞\n","   ‚úÖ Acc@15¬∞: 35.0%\n","   ‚úÖ Acc@30¬∞: 55.3%\n","   ‚úÖ Acc@45¬∞: 71.0%\n","   ‚è±Ô∏è  Time: 0.17 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 75/100: lr0p00022_bs32_wd0p0002_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 61.14¬∞\n","   ‚úÖ Acc@15¬∞: 35.7%\n","   ‚úÖ Acc@30¬∞: 56.7%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.26 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 76/100: lr0p00022_bs32_wd0p0002_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 2e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.64¬∞\n","   ‚úÖ Acc@15¬∞: 35.3%\n","   ‚úÖ Acc@30¬∞: 58.3%\n","   ‚úÖ Acc@45¬∞: 73.3%\n","   ‚è±Ô∏è  Time: 0.22 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 77/100: lr0p00022_bs32_wd0p0005_dr0p50\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.5\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.79¬∞\n","   ‚úÖ Acc@15¬∞: 35.3%\n","   ‚úÖ Acc@30¬∞: 58.3%\n","   ‚úÖ Acc@45¬∞: 73.7%\n","   ‚è±Ô∏è  Time: 0.18 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 78/100: lr0p00022_bs32_wd0p0005_dr0p55\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 58.29¬∞\n","   ‚úÖ Acc@15¬∞: 32.0%\n","   ‚úÖ Acc@30¬∞: 54.0%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.15 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 79/100: lr0p00022_bs32_wd0p0005_dr0p60\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.6\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 60.73¬∞\n","   ‚úÖ Acc@15¬∞: 33.3%\n","   ‚úÖ Acc@30¬∞: 57.3%\n","   ‚úÖ Acc@45¬∞: 72.0%\n","   ‚è±Ô∏è  Time: 0.16 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 80/100: lr0p00022_bs32_wd0p0005_dr0p65\n","======================================================================\n","   LR: 2e-04, Batch: 32, WD: 5e-04, Dropout: 0.65\n","   Effective Batch: 64\n","\n","   ‚úÖ Best Val MAE: 63.80¬∞\n","   ‚úÖ Acc@15¬∞: 31.3%\n","   ‚úÖ Acc@30¬∞: 53.3%\n","   ‚úÖ Acc@45¬∞: 69.7%\n","   ‚è±Ô∏è  Time: 0.18 hours\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","======================================================================\n","üîß Experiment 81/100: lr0p00025_bs32_wd0_dr0p50\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 0e+00, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 82/100: lr0p00025_bs32_wd0_dr0p55\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 0e+00, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 83/100: lr0p00025_bs32_wd0_dr0p60\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 0e+00, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 84/100: lr0p00025_bs32_wd0_dr0p65\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 0e+00, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 85/100: lr0p00025_bs32_wd0p00005_dr0p50\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-05, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 86/100: lr0p00025_bs32_wd0p00005_dr0p55\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-05, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 87/100: lr0p00025_bs32_wd0p00005_dr0p60\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-05, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 88/100: lr0p00025_bs32_wd0p00005_dr0p65\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-05, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 89/100: lr0p00025_bs32_wd0p0001_dr0p50\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 1e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 90/100: lr0p00025_bs32_wd0p0001_dr0p55\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 1e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 91/100: lr0p00025_bs32_wd0p0001_dr0p60\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 1e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 92/100: lr0p00025_bs32_wd0p0001_dr0p65\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 1e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 93/100: lr0p00025_bs32_wd0p0002_dr0p50\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 2e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 94/100: lr0p00025_bs32_wd0p0002_dr0p55\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 2e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 95/100: lr0p00025_bs32_wd0p0002_dr0p60\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 2e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 96/100: lr0p00025_bs32_wd0p0002_dr0p65\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 2e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 97/100: lr0p00025_bs32_wd0p0005_dr0p50\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-04, Dropout: 0.5\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 98/100: lr0p00025_bs32_wd0p0005_dr0p55\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 99/100: lr0p00025_bs32_wd0p0005_dr0p60\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-04, Dropout: 0.6\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üîß Experiment 100/100: lr0p00025_bs32_wd0p0005_dr0p65\n","======================================================================\n","   LR: 3e-04, Batch: 32, WD: 5e-04, Dropout: 0.65\n","   Effective Batch: 64\n","   ‚è≠Ô∏è  Already completed, skipping...\n","\n","======================================================================\n","üéâ HYPERPARAMETER TUNING COMPLETED!\n","======================================================================\n","‚úÖ Completed: 40\n","‚è≠Ô∏è  Skipped: 60\n","üìä Total results: 100\n","======================================================================\n","\n","üìä Results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","\n","üèÜ TOP 10 RESULTS:\n","======================================================================\n","1. lr1.5e-04_bs32_wd5e-04_dr0.55\n","   MAE: 51.39¬∞ | Acc@15¬∞: 35.0% | Acc@30¬∞: 57.3%\n","2. lr1.8e-04_bs32_wd5e-04_dr0.60\n","   MAE: 53.30¬∞ | Acc@15¬∞: 34.7% | Acc@30¬∞: 58.0%\n","3. lr3e-04_bs32_wd2e-04_dr0.50\n","   MAE: 53.70¬∞ | Acc@15¬∞: 32.7% | Acc@30¬∞: 58.7%\n","4. lr2e-04_bs32_wd2e-04_dr0.65\n","   MAE: 54.77¬∞ | Acc@15¬∞: 36.3% | Acc@30¬∞: 59.0%\n","5. lr0p00018_bs32_wd0p0005_dr0p65\n","   MAE: 55.84¬∞ | Acc@15¬∞: 34.7% | Acc@30¬∞: 60.7%\n","6. lr1e-04_bs32_wd2e-04_dr0.50\n","   MAE: 56.07¬∞ | Acc@15¬∞: 38.0% | Acc@30¬∞: 60.3%\n","7. lr0p0002_bs32_wd0p0002_dr0p65\n","   MAE: 56.19¬∞ | Acc@15¬∞: 33.0% | Acc@30¬∞: 57.0%\n","8. lr1e-04_bs32_wd5e-04_dr0.60\n","   MAE: 56.40¬∞ | Acc@15¬∞: 35.0% | Acc@30¬∞: 58.3%\n","9. lr1e-04_bs32_wd2e-04_dr0.65\n","   MAE: 56.51¬∞ | Acc@15¬∞: 35.3% | Acc@30¬∞: 58.0%\n","10. lr0p0002_bs32_wd0_dr0p55\n","   MAE: 56.95¬∞ | Acc@15¬∞: 36.0% | Acc@30¬∞: 57.7%\n","======================================================================\n"]}],"source":["# DEBUG: Check for duplicates\n","print(\"üîç Checking for duplicate experiment names...\")\n","from collections import Counter\n","\n","param_combinations_test = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","exp_names = []\n","for lr, bs, wd, dropout in param_combinations_test:\n","    params = {'learning_rate': lr, 'batch_size': bs, 'weight_decay': wd, 'dropout': dropout}\n","    exp_name = get_experiment_name(params)\n","    exp_names.append(exp_name)\n","\n","# Check for duplicates\n","name_counts = Counter(exp_names)\n","duplicates = {name: count for name, count in name_counts.items() if count > 1}\n","\n","if duplicates:\n","    print(f\"‚ùå Found {len(duplicates)} duplicate names:\")\n","    for name, count in list(duplicates.items())[:5]:\n","        print(f\"   {name}: appears {count} times\")\n","else:\n","    print(f\"‚úÖ All {len(exp_names)} experiment names are unique!\")\n","\n","print(f\"\\nüìä First 5 experiment names:\")\n","for i, name in enumerate(exp_names[:5]):\n","    print(f\"   {i+1}. {name}\")\n","\n","print(f\"\\nüìä Last 5 experiment names:\")\n","for i, name in enumerate(exp_names[-5:], len(exp_names)-4):\n","    print(f\"   {i}. {name}\")\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ STARTING HYPERPARAMETER TUNING\")\n","print(\"=\"*70)\n","\n","# Create results directory\n","results_dir = Path(BASE_CONFIG['results_dir'])\n","results_dir.mkdir(parents=True, exist_ok=True)\n","\n","# Generate all combinations\n","param_combinations = list(itertools.product(\n","    HYPERPARAMETER_GRID['learning_rate'],\n","    HYPERPARAMETER_GRID['batch_size'],\n","    HYPERPARAMETER_GRID['weight_decay'],\n","    HYPERPARAMETER_GRID['dropout']\n","))\n","\n","print(f\"\\nüìä Total combinations to test: {len(param_combinations)}\")\n","print(f\"‚öôÔ∏è  Mixed Precision: {FIXED_PARAMS['use_amp']}\")\n","print(f\"‚öôÔ∏è  Gradient Accumulation: {FIXED_PARAMS['gradient_accumulation_steps']}x\")\n","\n","# Track all results\n","all_results = []\n","completed_count = 0\n","skipped_count = 0\n","\n","for idx, (lr, bs, wd, dropout) in enumerate(param_combinations, 1):\n","    params = {\n","        'learning_rate': lr,\n","        'batch_size': bs,\n","        'weight_decay': wd,\n","        'dropout': dropout\n","    }\n","\n","    exp_name = get_experiment_name(params)\n","\n","    print(f\"\\n{'='*70}\")\n","    print(f\"üîß Experiment {idx}/{len(param_combinations)}: {exp_name}\")\n","    print(f\"{'='*70}\")\n","    print(f\"   LR: {lr:.0e}, Batch: {bs}, WD: {wd:.0e}, Dropout: {dropout}\")\n","    print(f\"   Effective Batch: {bs * FIXED_PARAMS['gradient_accumulation_steps']}\")\n","\n","    # Check if already completed\n","    if check_if_completed(results_dir, exp_name):\n","        print(f\"   ‚è≠Ô∏è  Already completed, skipping...\")\n","        skipped_count += 1\n","\n","        # Load existing result\n","        with open(results_dir / exp_name / 'result.json', 'r') as f:\n","            result = json.load(f)\n","        all_results.append(result)\n","        continue\n","\n","    try:\n","        # Create data loaders with current batch size\n","        train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=bs,\n","            shuffle=True,\n","            num_workers=BASE_CONFIG['num_workers'],\n","            pin_memory=BASE_CONFIG['pin_memory']\n","        )\n","\n","        val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=bs,\n","            shuffle=False,\n","            num_workers=BASE_CONFIG['num_workers'],\n","            pin_memory=BASE_CONFIG['pin_memory']\n","        )\n","\n","        # Train\n","        result = train_single_experiment(\n","            params, train_loader, val_loader, device, results_dir\n","        )\n","\n","        all_results.append(result)\n","        completed_count += 1\n","\n","        print(f\"\\n   ‚úÖ Best Val MAE: {result['best_val_mae']:.2f}¬∞\")\n","        print(f\"   ‚úÖ Acc@15¬∞: {result['best_val_acc15']:.1f}%\")\n","        print(f\"   ‚úÖ Acc@30¬∞: {result['best_val_acc30']:.1f}%\")\n","        print(f\"   ‚úÖ Acc@45¬∞: {result['best_val_acc45']:.1f}%\")\n","        print(f\"   ‚è±Ô∏è  Time: {result['training_time_hours']:.2f} hours\")\n","\n","        # Save results to Excel after each experiment\n","        save_results_to_excel(results_dir, all_results)\n","\n","        # Clear GPU cache\n","        torch.cuda.empty_cache()\n","\n","    except Exception as e:\n","        print(f\"\\n   ‚ùå Error in experiment {exp_name}: {str(e)}\")\n","        continue\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ HYPERPARAMETER TUNING COMPLETED!\")\n","print(\"=\"*70)\n","print(f\"‚úÖ Completed: {completed_count}\")\n","print(f\"‚è≠Ô∏è  Skipped: {skipped_count}\")\n","print(f\"üìä Total results: {len(all_results)}\")\n","print(\"=\"*70)\n","\n","# Final save\n","if all_results:\n","    excel_file = save_results_to_excel(results_dir, all_results)\n","\n","    # Show top 10 results\n","    sorted_results = sorted(all_results, key=lambda x: x['best_val_mae'])\n","    print(\"\\nüèÜ TOP 10 RESULTS:\")\n","    print(\"=\"*70)\n","    for i, res in enumerate(sorted_results[:10], 1):\n","        print(f\"{i}. {res['experiment_name']}\")\n","        print(f\"   MAE: {res['best_val_mae']:.2f}¬∞ | Acc@15¬∞: {res['best_val_acc15']:.1f}% | Acc@30¬∞: {res['best_val_acc30']:.1f}%\")\n","    print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{"id":"e0FplEL-7O6f"},"source":["## 11. Analyze Results"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"nDMD7OmV7O6f","executionInfo":{"status":"ok","timestamp":1766529520293,"user_tz":-180,"elapsed":55,"user":{"displayName":"ofcosar","userId":"12337476720676369762"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"664eabc7-c06f-47d7-ca7f-92b32db56b81"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä HYPERPARAMETER ANALYSIS\n","======================================================================\n","\n","ü•á BEST CONFIGURATION:\n","   Experiment: lr1.5e-04_bs32_wd5e-04_dr0.55\n","   LR: 1e-04, Batch: 32, WD: 5e-04, Dropout: 0.55\n","   Val MAE: 51.39¬∞\n","   Acc@15¬∞: 35.0%\n","   Acc@30¬∞: 57.3%\n","   Acc@45¬∞: 74.0%\n","   Training time: 0.19 hours\n","\n","üìà OVERALL STATISTICS:\n","   Mean Val MAE: 60.86¬∞\n","   Std Val MAE: 3.47¬∞\n","   Min Val MAE: 51.39¬∞\n","   Max Val MAE: 69.67¬∞\n","\n","   Mean Acc@30¬∞: 56.4%\n","   Max Acc@30¬∞: 60.7%\n","\n","üìä BEST BY LEARNING RATE:\n","   LR 1e-04: MAE 51.39¬∞ | Acc@30¬∞ 57.3%\n","   LR 2e-04: MAE 53.30¬∞ | Acc@30¬∞ 58.0%\n","   LR 2e-04: MAE 56.19¬∞ | Acc@30¬∞ 57.0%\n","   LR 2e-04: MAE 57.01¬∞ | Acc@30¬∞ 60.7%\n","   LR 3e-04: MAE 53.70¬∞ | Acc@30¬∞ 58.7%\n","\n","üìä BEST BY BATCH SIZE:\n","   Batch  32: MAE 51.39¬∞ | Acc@30¬∞ 57.3%\n","\n","======================================================================\n","üìÅ Full results saved to: /content/drive/MyDrive/hyperparameter_tuning_results_round2_fixed/hyperparameter_tuning_results.xlsx\n","======================================================================\n"]}],"source":["# Load results from Excel\n","excel_file = Path(BASE_CONFIG['results_dir']) / 'hyperparameter_tuning_results.xlsx'\n","\n","if excel_file.exists():\n","    df = pd.read_excel(excel_file)\n","\n","    print(\"\\nüìä HYPERPARAMETER ANALYSIS\")\n","    print(\"=\"*70)\n","\n","    # Best overall\n","    best = df.iloc[0]\n","    print(f\"\\nü•á BEST CONFIGURATION:\")\n","    print(f\"   Experiment: {best['experiment_name']}\")\n","    print(f\"   LR: {best['learning_rate']:.0e}, Batch: {best['batch_size']}, WD: {best['weight_decay']:.0e}, Dropout: {best['dropout']}\")\n","    print(f\"   Val MAE: {best['best_val_mae']:.2f}¬∞\")\n","    print(f\"   Acc@15¬∞: {best['best_val_acc15']:.1f}%\")\n","    print(f\"   Acc@30¬∞: {best['best_val_acc30']:.1f}%\")\n","    print(f\"   Acc@45¬∞: {best['best_val_acc45']:.1f}%\")\n","    print(f\"   Training time: {best['training_time_hours']:.2f} hours\")\n","\n","    # Statistics\n","    print(f\"\\nüìà OVERALL STATISTICS:\")\n","    print(f\"   Mean Val MAE: {df['best_val_mae'].mean():.2f}¬∞\")\n","    print(f\"   Std Val MAE: {df['best_val_mae'].std():.2f}¬∞\")\n","    print(f\"   Min Val MAE: {df['best_val_mae'].min():.2f}¬∞\")\n","    print(f\"   Max Val MAE: {df['best_val_mae'].max():.2f}¬∞\")\n","    print(f\"\\n   Mean Acc@30¬∞: {df['best_val_acc30'].mean():.1f}%\")\n","    print(f\"   Max Acc@30¬∞: {df['best_val_acc30'].max():.1f}%\")\n","\n","    # Best by learning rate\n","    print(f\"\\nüìä BEST BY LEARNING RATE:\")\n","    for lr in sorted(df['learning_rate'].unique()):\n","        lr_df = df[df['learning_rate'] == lr]\n","        best_lr = lr_df.iloc[0]\n","        print(f\"   LR {lr:.0e}: MAE {best_lr['best_val_mae']:.2f}¬∞ | Acc@30¬∞ {best_lr['best_val_acc30']:.1f}%\")\n","\n","    # Best by batch size\n","    print(f\"\\nüìä BEST BY BATCH SIZE:\")\n","    for bs in sorted(df['batch_size'].unique()):\n","        bs_df = df[df['batch_size'] == bs]\n","        best_bs = bs_df.iloc[0]\n","        print(f\"   Batch {bs:3d}: MAE {best_bs['best_val_mae']:.2f}¬∞ | Acc@30¬∞ {best_bs['best_val_acc30']:.1f}%\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(f\"üìÅ Full results saved to: {excel_file}\")\n","    print(\"=\"*70)\n","else:\n","    print(\"‚ö†Ô∏è No results file found. Run the tuning experiment first!\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}